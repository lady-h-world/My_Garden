{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a712d351",
   "metadata": {},
   "source": [
    "Licensed under the MIT License.\n",
    "\n",
    "Copyright (c) 2025-2035. All rights reserved by Hanhan Wu.\n",
    "\n",
    "Permission is hereby granted to view this code for evaluation purposes only.\n",
    "You may not reuse, copy, modify, merge, publish, distribute, sublicense,\n",
    "or exploit this code without Hanhan Wu's EXPLICIT written permission.\n",
    "\n",
    "\n",
    "# DsPy on Bigger FIQA Data & Optimize Answer Generation\n",
    "\n",
    "* Dataset\n",
    "  * 100 training records\n",
    "  * 180 validation records"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cac65eed",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import pandas as pd\n",
    "import dspy\n",
    "import contextlib\n",
    "from concurrent.futures import ThreadPoolExecutor, as_completed\n",
    "\n",
    "from utils import *\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "\n",
    "model_str = 'gpt-4.1-nano'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1eaa753d",
   "metadata": {},
   "source": [
    "### Load Data Input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ffecc76a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(100, 4) (180, 4)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>doc_id</th>\n",
       "      <th>context</th>\n",
       "      <th>question</th>\n",
       "      <th>ground_truth</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2574.jpeg</td>\n",
       "      <td>[**Document Type:** \\nThis is a check issued b...</td>\n",
       "      <td>Who issued the check?</td>\n",
       "      <td>The Tobacco Institute, located at 1875 I Stree...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4492.jpeg</td>\n",
       "      <td>[### Document Analysis\\n\\n**Document Type**: C...</td>\n",
       "      <td>What is the type of document being analyzed?</td>\n",
       "      <td>The document is a Check Request Form.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>7281.jpeg</td>\n",
       "      <td>[**Document Type**: This is a commercial invoi...</td>\n",
       "      <td>What is the name of the organization issuing t...</td>\n",
       "      <td>Philip Morris Limited</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1242.jpeg</td>\n",
       "      <td>[### Document Type\\nThis is a financial docume...</td>\n",
       "      <td>What is the client company for this outdoor ad...</td>\n",
       "      <td>The client company is P.M. Inc.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7700.jpeg</td>\n",
       "      <td>[### Document Type\\nThis is a Production Estim...</td>\n",
       "      <td>What is the client's name mentioned in the doc...</td>\n",
       "      <td>The client's name is RJR/NOW Family.</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      doc_id                                            context  \\\n",
       "0  2574.jpeg  [**Document Type:** \\nThis is a check issued b...   \n",
       "1  4492.jpeg  [### Document Analysis\\n\\n**Document Type**: C...   \n",
       "2  7281.jpeg  [**Document Type**: This is a commercial invoi...   \n",
       "3  1242.jpeg  [### Document Type\\nThis is a financial docume...   \n",
       "4  7700.jpeg  [### Document Type\\nThis is a Production Estim...   \n",
       "\n",
       "                                            question  \\\n",
       "0                              Who issued the check?   \n",
       "1       What is the type of document being analyzed?   \n",
       "2  What is the name of the organization issuing t...   \n",
       "3  What is the client company for this outdoor ad...   \n",
       "4  What is the client's name mentioned in the doc...   \n",
       "\n",
       "                                        ground_truth  \n",
       "0  The Tobacco Institute, located at 1875 I Stree...  \n",
       "1              The document is a Check Request Form.  \n",
       "2                              Philip Morris Limited  \n",
       "3                    The client company is P.M. Inc.  \n",
       "4               The client's name is RJR/NOW Family.  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df = pd.read_parquet('final_finance_qa_train.parquet')\n",
    "val_df = pd.read_parquet('final_finance_qa_val.parquet')\n",
    "\n",
    "print(train_df.shape, val_df.shape)\n",
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "01f6506c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100 180\n",
      "Example({'question': 'Who issued the check?', 'context': ['**Document Type:** \\nThis is a check issued by The Tobacco Institute.\\n\\n**Key Details:**\\n- **Issuer:** The Tobacco Institute, 1875 I Street, Northwest, Washington, DC 20006\\n- **Check Number:** 075013\\n- **Date:** September 7, 1990\\n- **Payee:** Citizens for Jim Mcpike\\n- **Amount:** $500.00\\n- **Check Status:** Non-Negotiable\\n- **Bank Details:** Check drawn from The National Bank\\n\\n**Insights and Observations:**\\n- The check is marked as non-negotiable, indicating it cannot be transferred and can only be cashed or deposited by the person named (Citizens for Jim Mcpike).\\n- The substantial amount (considering the date in 1990) suggests it might have been for a significant expense or donation.\\n- As the issuer is The Tobacco Institute, the payment could be related to lobbying or campaign activities, given that it is addressed to a political entity or initiative named after an individual, Jim Mcpike.\\n- The documentâ€™s age and historical context could be relevant in analyzing the financial operations and political influences of organizations such as The Tobacco Institute during that period.\\n- The date and amount could be useful in financial or historical audits for tracing fund flows or understanding the financial practices of corporate entities in political realms at the time.'], 'ground_truth': 'The Tobacco Institute, located at 1875 I Street, Northwest, Washington, DC 20006.'}) (input_keys={'context', 'question'})\n"
     ]
    }
   ],
   "source": [
    "# the trainset, devset for DsPy\n",
    "dspy_trainset = [\n",
    "    dspy.Example({\n",
    "        \"question\": record['question'],\n",
    "        \"context\": list(record['context']),\n",
    "        \"ground_truth\": record['ground_truth']\n",
    "        }).with_inputs('question', 'context')\n",
    "    for record in train_df.to_dict(orient='records')\n",
    "]\n",
    "\n",
    "dspy_valset = [\n",
    "    dspy.Example({\n",
    "        \"question\": record['question'],\n",
    "        \"context\": list(record['context']),\n",
    "        \"ground_truth\": record['ground_truth']\n",
    "        }).with_inputs('question', 'context')\n",
    "    for record in val_df.to_dict(orient='records')\n",
    "]\n",
    "\n",
    "print(len(dspy_trainset), len(dspy_valset))\n",
    "print(dspy_trainset[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd4c1467",
   "metadata": {},
   "source": [
    "### Prompt Optimization with DsPy\n",
    "\n",
    "* Time Cost\n",
    "  * 18 mins for compilation\n",
    "* Metrics is based on DeepEval's G-eval: https://deepeval.com/docs/metrics-llm-evals\n",
    "  * The G-eval implemented here measures answer quality by checking both ground truth and context"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "029852f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import dspy\n",
    "from dspy.teleprompt import MIPROv2\n",
    "\n",
    "\n",
    "llm = dspy.LM(f\"openai/{model_str}\")\n",
    "dspy.settings.configure(lm=llm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "035b1ebf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Devset] Question: What is the date of the invoice?\n",
      "[Devset] Ground Truth: The invoice date is August 28, 1978.\n",
      "[Prediction] Predicted Answer: August 28, 1978\n",
      "[Prediction] Reasoning: The document clearly states the invoice date as August 28, 1978. This date is explicitly labeled under \"Invoice Date,\" making it the definitive date of the invoice. Other dates mentioned, such as the received date and handwritten notes, do not alter the primary invoice date. Therefore, the answer should be the date provided directly in the invoice details.\n"
     ]
    }
   ],
   "source": [
    "class GenerateAnswer(dspy.Signature):\n",
    "    \"\"\"Answer questions with short factoid answers.\n",
    "        You will receive context(contain relevant facts).\n",
    "        Think step by step.\"\"\"  # this is the initial prompt\n",
    "    question = dspy.InputField(desc=\"the question to answer\")\n",
    "    context = dspy.InputField(desc=\"retrieved context, may contain relevant facts\")\n",
    "    answer = dspy.OutputField(desc=\"AI's answer\")\n",
    "\n",
    "\n",
    "class RAG_AnswerGeneration(dspy.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.generate_answer = dspy.ChainOfThought(GenerateAnswer)\n",
    "\n",
    "    def forward(self, question, context):\n",
    "        prediction = self.generate_answer(question=question, context=context)\n",
    "        return dspy.Prediction(context=context,\n",
    "                               answer=prediction.answer,\n",
    "                               reasoning=prediction.reasoning)\n",
    "\n",
    "\n",
    "# example input & output BEFORE prompt optimization\n",
    "dev_example = dspy_valset[10]\n",
    "generate_answer = RAG_AnswerGeneration()\n",
    "pred = generate_answer(question=dev_example.question,\n",
    "                       context=dev_example.context)\n",
    "print(f\"[Devset] Question: {dev_example.question}\")\n",
    "print(f\"[Devset] Ground Truth: {dev_example.ground_truth}\")\n",
    "print(f\"[Prediction] Predicted Answer: {pred.answer}\")\n",
    "print(f\"[Prediction] Reasoning: {pred.reasoning}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fe609cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def answer_correctness_geval(example, prediction):\n",
    "    ground_truth = example.ground_truth.strip().lower()\n",
    "    ai_answer = prediction.answer.strip().lower()\n",
    "    \n",
    "    correctness_metric = GEval(\n",
    "\t\t    name=\"Answer Correctness\",\n",
    "            model=model_str,\n",
    "\t\t    criteria=\"Determine whether the ai_answer aligns with the ground_truth and the context.\",\n",
    "\t\t    evaluation_params=[LLMTestCaseParams.ACTUAL_OUTPUT,\n",
    "\t\t\t\t\t\t       LLMTestCaseParams.EXPECTED_OUTPUT,\n",
    "                               LLMTestCaseParams.CONTEXT],\n",
    "\t\t)\n",
    "    test_case = LLMTestCase(\n",
    "        input=example.question,\n",
    "        context=example.context,\n",
    "        actual_output=ai_answer,\n",
    "        expected_output=ground_truth)\n",
    "    correctness_metric.measure(test_case)\n",
    "    score = correctness_metric.score\n",
    "\n",
    "    print(f\"\"\"[Trial] Q: {example.question} | Score: {score}\n",
    "                      GT: {ground_truth}\n",
    "                      Pred: {ai_answer}\n",
    "          \"\"\")\n",
    "    return score\n",
    "\n",
    "\n",
    "optimizer = MIPROv2(\n",
    "    metric=answer_correctness_geval,\n",
    "    prompt_model=llm,\n",
    "    task_model=llm,\n",
    "    num_candidates=5,  # number of proposed instructions\n",
    "    init_temperature=0.7,\n",
    "    seed=10,\n",
    "    auto=None,\n",
    "    verbose=True,\n",
    "    track_stats=True\n",
    ")\n",
    "\n",
    "\n",
    "with open('fiqa_dspy_miprov2_biggerdata.txt', 'w') as f:\n",
    "    with contextlib.redirect_stdout(f):\n",
    "        compiled_rag = optimizer.compile(\n",
    "            RAG_AnswerGeneration(),\n",
    "            trainset=dspy_trainset,\n",
    "            num_trials=5,\n",
    "            max_bootstrapped_demos=2,\n",
    "            max_labeled_demos=3,\n",
    "            minibatch_size=4,\n",
    "            requires_permission_to_run=False\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "077ab5de",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "generate_answer.predict = Predict(StringSignature(question, context -> reasoning, answer\n",
       "    instructions='Answer questions with short factoid answers.\\nYou will receive context(contain relevant facts).\\nThink step by step.'\n",
       "    question = Field(annotation=str required=True json_schema_extra={'desc': 'the question to answer', '__dspy_field_type': 'input', 'prefix': 'Question:'})\n",
       "    context = Field(annotation=str required=True json_schema_extra={'desc': 'retrieved context, may contain relevant facts', '__dspy_field_type': 'input', 'prefix': 'Context:'})\n",
       "    reasoning = Field(annotation=str required=True json_schema_extra={'prefix': \"Reasoning: Let's think step by step in order to\", 'desc': '${reasoning}', '__dspy_field_type': 'output'})\n",
       "    answer = Field(annotation=str required=True json_schema_extra={'desc': \"AI's answer\", '__dspy_field_type': 'output', 'prefix': 'Answer:'})\n",
       "))"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "compiled_rag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e772b1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "compiled_rag.save(\"dspy_compiled_rag.json\", save_program=False)  # save the optimized program in JSON format\n",
    "compiled_rag.save(\"dspy_compiled_rag/\", save_program=True)  # save the compiled program for later reuse"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2a0b649",
   "metadata": {},
   "source": [
    "### Apply Optimized Prompt on Valset\n",
    "\n",
    "* Generate answer after prompt optimization\n",
    "* Compare `answer_after_prompt_opt` with `ground_truth`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "85f830aa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(180, 5)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>question</th>\n",
       "      <th>context</th>\n",
       "      <th>ground_truth</th>\n",
       "      <th>answer_after_prompt_opt</th>\n",
       "      <th>ai_answer_reasoning</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>What is the objective of Vitality Tests?</td>\n",
       "      <td>[### Document Type\\nThe image appears to be a ...</td>\n",
       "      <td>The objective of Vitality Tests is to determin...</td>\n",
       "      <td>To determine VRL's responsiveness to increased...</td>\n",
       "      <td>The objective of Vitality Tests is to determin...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>What is the company name and address listed on...</td>\n",
       "      <td>[### Document Type\\nThe image depicts an invoi...</td>\n",
       "      <td>The company name is Copiadora Gouldsvey, and t...</td>\n",
       "      <td>Company Name: Copiadora Gouldsvey\\nAddress: 12...</td>\n",
       "      <td>The question asks for the company name and add...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Who is the issuer of the invoice?</td>\n",
       "      <td>[### Document Type\\nThis is an invoice from En...</td>\n",
       "      <td>Entertainment Partners, EPSG Talent Services</td>\n",
       "      <td>Entertainment Partners, EPSG Talent Services</td>\n",
       "      <td>The invoice explicitly states that the issuer ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Who is the issuer of the invoice?</td>\n",
       "      <td>[**Document Type:**\\n- This image shows an inv...</td>\n",
       "      <td>Fannon-Luers Associates Inc.</td>\n",
       "      <td>Fannon-Luers Associates Inc.</td>\n",
       "      <td>The question asks for the issuer of the invoic...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Who is the issuer of the check?</td>\n",
       "      <td>[### Document Type\\nThe document is a check.\\n...</td>\n",
       "      <td>The issuer of the check is the Center for Indo...</td>\n",
       "      <td>Center for Indoor Air Research, Linthicum, MD ...</td>\n",
       "      <td>The issuer of the check is identified in the k...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            question  \\\n",
       "0           What is the objective of Vitality Tests?   \n",
       "1  What is the company name and address listed on...   \n",
       "2                  Who is the issuer of the invoice?   \n",
       "3                  Who is the issuer of the invoice?   \n",
       "4                    Who is the issuer of the check?   \n",
       "\n",
       "                                             context  \\\n",
       "0  [### Document Type\\nThe image appears to be a ...   \n",
       "1  [### Document Type\\nThe image depicts an invoi...   \n",
       "2  [### Document Type\\nThis is an invoice from En...   \n",
       "3  [**Document Type:**\\n- This image shows an inv...   \n",
       "4  [### Document Type\\nThe document is a check.\\n...   \n",
       "\n",
       "                                        ground_truth  \\\n",
       "0  The objective of Vitality Tests is to determin...   \n",
       "1  The company name is Copiadora Gouldsvey, and t...   \n",
       "2       Entertainment Partners, EPSG Talent Services   \n",
       "3                       Fannon-Luers Associates Inc.   \n",
       "4  The issuer of the check is the Center for Indo...   \n",
       "\n",
       "                             answer_after_prompt_opt  \\\n",
       "0  To determine VRL's responsiveness to increased...   \n",
       "1  Company Name: Copiadora Gouldsvey\\nAddress: 12...   \n",
       "2       Entertainment Partners, EPSG Talent Services   \n",
       "3                       Fannon-Luers Associates Inc.   \n",
       "4  Center for Indoor Air Research, Linthicum, MD ...   \n",
       "\n",
       "                                 ai_answer_reasoning  \n",
       "0  The objective of Vitality Tests is to determin...  \n",
       "1  The question asks for the company name and add...  \n",
       "2  The invoice explicitly states that the issuer ...  \n",
       "3  The question asks for the issuer of the invoic...  \n",
       "4  The issuer of the check is identified in the k...  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results = []\n",
    "for r in dspy_valset:\n",
    "    pred = compiled_rag(question=r.question, context=r.context)\n",
    "    results.append({\n",
    "        \"question\": r.question,\n",
    "        \"context\": r.context,\n",
    "        \"ground_truth\": r.ground_truth,\n",
    "        \"answer_after_prompt_opt\": pred.answer,\n",
    "        \"ai_answer_reasoning\": pred.reasoning,\n",
    "    })\n",
    "\n",
    "results_df = pd.DataFrame(results)\n",
    "print(results_df.shape)\n",
    "results_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2bed111a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_record(record):\n",
    "    eval_score, eval_reason = my_deepeval_answer_correctness(\n",
    "        record['question'], list(record['context']),\n",
    "        record['ground_truth'],\n",
    "        record['answer_after_prompt_opt']\n",
    "    )\n",
    "    record['eval_score'] = eval_score\n",
    "    record['eval_reason'] = eval_reason\n",
    "    return record\n",
    "\n",
    "final_eval_lst = []\n",
    "with ThreadPoolExecutor(max_workers=8) as executor:\n",
    "    futures = [executor.submit(process_record, record) for record in results]\n",
    "    for future in as_completed(futures):\n",
    "        final_eval_lst.append(future.result())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b438c539",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(180, 7)\n",
      "0.7607632596008781\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>question</th>\n",
       "      <th>context</th>\n",
       "      <th>ground_truth</th>\n",
       "      <th>answer_after_prompt_opt</th>\n",
       "      <th>ai_answer_reasoning</th>\n",
       "      <th>eval_score</th>\n",
       "      <th>eval_reason</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Who is the issuer of the check?</td>\n",
       "      <td>[### Document Type\\nThe document is a check.\\n...</td>\n",
       "      <td>The issuer of the check is the Center for Indo...</td>\n",
       "      <td>Center for Indoor Air Research, Linthicum, MD ...</td>\n",
       "      <td>The issuer of the check is identified in the k...</td>\n",
       "      <td>0.720855</td>\n",
       "      <td>The Actual Output correctly identifies the iss...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>What is the objective of Vitality Tests?</td>\n",
       "      <td>[### Document Type\\nThe image appears to be a ...</td>\n",
       "      <td>The objective of Vitality Tests is to determin...</td>\n",
       "      <td>To determine VRL's responsiveness to increased...</td>\n",
       "      <td>The objective of Vitality Tests is to determin...</td>\n",
       "      <td>0.717346</td>\n",
       "      <td>The Actual Output accurately states the object...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>What is the company name and address listed on...</td>\n",
       "      <td>[### Document Type\\nThe image depicts an invoi...</td>\n",
       "      <td>The company name is Copiadora Gouldsvey, and t...</td>\n",
       "      <td>Company Name: Copiadora Gouldsvey\\nAddress: 12...</td>\n",
       "      <td>The question asks for the company name and add...</td>\n",
       "      <td>0.910567</td>\n",
       "      <td>The Actual Output accurately reproduces the co...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Who is the issuer of the invoice?</td>\n",
       "      <td>[### Document Type\\nThis is an invoice from En...</td>\n",
       "      <td>Entertainment Partners, EPSG Talent Services</td>\n",
       "      <td>Entertainment Partners, EPSG Talent Services</td>\n",
       "      <td>The invoice explicitly states that the issuer ...</td>\n",
       "      <td>0.998901</td>\n",
       "      <td>The Actual Output matches the Expected Output ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>What is the document type of the financial per...</td>\n",
       "      <td>[**Document Type**: Financial Performance Summ...</td>\n",
       "      <td>The document type is a Financial Performance S...</td>\n",
       "      <td>Financial Performance Summary Report</td>\n",
       "      <td>The document explicitly states \"Document Type:...</td>\n",
       "      <td>0.701041</td>\n",
       "      <td>The Actual Output states 'Financial Performanc...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            question  \\\n",
       "0                    Who is the issuer of the check?   \n",
       "1           What is the objective of Vitality Tests?   \n",
       "2  What is the company name and address listed on...   \n",
       "3                  Who is the issuer of the invoice?   \n",
       "4  What is the document type of the financial per...   \n",
       "\n",
       "                                             context  \\\n",
       "0  [### Document Type\\nThe document is a check.\\n...   \n",
       "1  [### Document Type\\nThe image appears to be a ...   \n",
       "2  [### Document Type\\nThe image depicts an invoi...   \n",
       "3  [### Document Type\\nThis is an invoice from En...   \n",
       "4  [**Document Type**: Financial Performance Summ...   \n",
       "\n",
       "                                        ground_truth  \\\n",
       "0  The issuer of the check is the Center for Indo...   \n",
       "1  The objective of Vitality Tests is to determin...   \n",
       "2  The company name is Copiadora Gouldsvey, and t...   \n",
       "3       Entertainment Partners, EPSG Talent Services   \n",
       "4  The document type is a Financial Performance S...   \n",
       "\n",
       "                             answer_after_prompt_opt  \\\n",
       "0  Center for Indoor Air Research, Linthicum, MD ...   \n",
       "1  To determine VRL's responsiveness to increased...   \n",
       "2  Company Name: Copiadora Gouldsvey\\nAddress: 12...   \n",
       "3       Entertainment Partners, EPSG Talent Services   \n",
       "4               Financial Performance Summary Report   \n",
       "\n",
       "                                 ai_answer_reasoning  eval_score  \\\n",
       "0  The issuer of the check is identified in the k...    0.720855   \n",
       "1  The objective of Vitality Tests is to determin...    0.717346   \n",
       "2  The question asks for the company name and add...    0.910567   \n",
       "3  The invoice explicitly states that the issuer ...    0.998901   \n",
       "4  The document explicitly states \"Document Type:...    0.701041   \n",
       "\n",
       "                                         eval_reason  \n",
       "0  The Actual Output correctly identifies the iss...  \n",
       "1  The Actual Output accurately states the object...  \n",
       "2  The Actual Output accurately reproduces the co...  \n",
       "3  The Actual Output matches the Expected Output ...  \n",
       "4  The Actual Output states 'Financial Performanc...  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_eval_df = pd.DataFrame(final_eval_lst)\n",
    "print(final_eval_df.shape)\n",
    "print(final_eval_df['eval_score'].mean())\n",
    "final_eval_df.head()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
