{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "07ca39f3",
   "metadata": {},
   "source": [
    "Licensed under the MIT License.\n",
    "\n",
    "Copyright (c) 2025-2035. All rights reserved by Hanhan Wu.\n",
    "\n",
    "Permission is hereby granted to view this code for evaluation purposes only.\n",
    "You may not reuse, copy, modify, merge, publish, distribute, sublicense,\n",
    "or exploit this code without Hanhan Wu's EXPLICIT written permission.\n",
    "\n",
    "\n",
    "# AdalFlow on Bigger FIQA Data & Optimize Answer Generation\n",
    "\n",
    "* Dataset\n",
    "  * 30 training records\n",
    "  * 30 validation records\n",
    "  * 30 testing records\n",
    "* Optimization\n",
    "  * teacher generator for few-shot learning\n",
    "  * backward_engine & optimizer for text_grad optimization\n",
    "  * Added `self.configure_text_optimizer_helper()` to customize LLM used in the optimization\n",
    "  * Added `few_shot_demos` to add examples in training, indeed improved the performance here\n",
    "  * Added `regularization_fn` in `optimizer_config`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f045bba8",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import pandas as pd\n",
    "import re\n",
    "import json\n",
    "import matplotlib.pyplot as plt\n",
    "from pprint import pprint\n",
    "from dataclasses import dataclass, field\n",
    "from typing import Union, Dict, Callable, Any, Tuple\n",
    "\n",
    "import adalflow as adal\n",
    "from adalflow.datasets.hotpot_qa import HotPotQAData\n",
    "from adalflow.components.model_client.openai_client import OpenAIClient\n",
    "from adalflow.eval.g_eval import GEvalLLMJudge, GEvalJudgeEvaluator, NLGTask\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "\n",
    "model_str = \"gpt-4.1-nano\"\n",
    "gpt4_model = {\n",
    "    \"model_client\": OpenAIClient(),\n",
    "    \"model_kwargs\": {\n",
    "        \"model\": model_str,\n",
    "        \"temperature\": 0.7,\n",
    "    },\n",
    "}\n",
    "model_kwargs = {\n",
    "        \"model\": model_str,\n",
    "        \"temperature\": 0.7,\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d941ed71",
   "metadata": {},
   "source": [
    "### Create Data Input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "28d25d1b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(30, 4) (30, 4) (30, 4)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>doc_id</th>\n",
       "      <th>context</th>\n",
       "      <th>question</th>\n",
       "      <th>ground_truth</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1361.jpeg</td>\n",
       "      <td>[### Document Type\\nThe document is an adverti...</td>\n",
       "      <td>What is the client company for this financial ...</td>\n",
       "      <td>The client company is P.M. Inc.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>8297.jpeg</td>\n",
       "      <td>[### Document Type\\nThe image depicts an invoi...</td>\n",
       "      <td>What is the company name and address listed on...</td>\n",
       "      <td>The company name is Copiadora Gouldsvey, and t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2319.jpeg</td>\n",
       "      <td>[### Document Type\\nThis image presents a fina...</td>\n",
       "      <td>What is the total farm cash receipts from 1988...</td>\n",
       "      <td>The total farm cash receipts over the period 1...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>6605.jpeg</td>\n",
       "      <td>[**Document Type:**  \\nThis is an invoice from...</td>\n",
       "      <td>Who is the issuer of the invoice?</td>\n",
       "      <td>Heyl &amp; Patterson</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7974.jpeg</td>\n",
       "      <td>[**Document Type**: The image features an Invo...</td>\n",
       "      <td>What is the invoice number of the document?</td>\n",
       "      <td>The invoice number is 3195004.</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      doc_id                                            context  \\\n",
       "0  1361.jpeg  [### Document Type\\nThe document is an adverti...   \n",
       "1  8297.jpeg  [### Document Type\\nThe image depicts an invoi...   \n",
       "2  2319.jpeg  [### Document Type\\nThis image presents a fina...   \n",
       "3  6605.jpeg  [**Document Type:**  \\nThis is an invoice from...   \n",
       "4  7974.jpeg  [**Document Type**: The image features an Invo...   \n",
       "\n",
       "                                            question  \\\n",
       "0  What is the client company for this financial ...   \n",
       "1  What is the company name and address listed on...   \n",
       "2  What is the total farm cash receipts from 1988...   \n",
       "3                  Who is the issuer of the invoice?   \n",
       "4        What is the invoice number of the document?   \n",
       "\n",
       "                                        ground_truth  \n",
       "0                    The client company is P.M. Inc.  \n",
       "1  The company name is Copiadora Gouldsvey, and t...  \n",
       "2  The total farm cash receipts over the period 1...  \n",
       "3                                   Heyl & Patterson  \n",
       "4                     The invoice number is 3195004.  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df = pd.read_parquet('final_finance_qa_train.parquet')\n",
    "val_df = pd.read_parquet('final_finance_qa_val.parquet')\n",
    "test_df = pd.read_parquet('final_finance_qa_test.parquet')\n",
    "\n",
    "print(train_df.shape, val_df.shape, test_df.shape)\n",
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b72a69af",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(90, 4)\n",
      "(90, 3)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>question</th>\n",
       "      <th>context</th>\n",
       "      <th>ground_truth</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>What is the client company for this financial ...</td>\n",
       "      <td>[### Document Type\\nThe document is an adverti...</td>\n",
       "      <td>The client company is P.M. Inc.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>What is the company name and address listed on...</td>\n",
       "      <td>[### Document Type\\nThe image depicts an invoi...</td>\n",
       "      <td>The company name is Copiadora Gouldsvey, and t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>What is the total farm cash receipts from 1988...</td>\n",
       "      <td>[### Document Type\\nThis image presents a fina...</td>\n",
       "      <td>The total farm cash receipts over the period 1...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Who is the issuer of the invoice?</td>\n",
       "      <td>[**Document Type:**  \\nThis is an invoice from...</td>\n",
       "      <td>Heyl &amp; Patterson</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>What is the invoice number of the document?</td>\n",
       "      <td>[**Document Type**: The image features an Invo...</td>\n",
       "      <td>The invoice number is 3195004.</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            question  \\\n",
       "0  What is the client company for this financial ...   \n",
       "1  What is the company name and address listed on...   \n",
       "2  What is the total farm cash receipts from 1988...   \n",
       "3                  Who is the issuer of the invoice?   \n",
       "4        What is the invoice number of the document?   \n",
       "\n",
       "                                             context  \\\n",
       "0  [### Document Type\\nThe document is an adverti...   \n",
       "1  [### Document Type\\nThe image depicts an invoi...   \n",
       "2  [### Document Type\\nThis image presents a fina...   \n",
       "3  [**Document Type:**  \\nThis is an invoice from...   \n",
       "4  [**Document Type**: The image features an Invo...   \n",
       "\n",
       "                                        ground_truth  \n",
       "0                    The client company is P.M. Inc.  \n",
       "1  The company name is Copiadora Gouldsvey, and t...  \n",
       "2  The total farm cash receipts over the period 1...  \n",
       "3                                   Heyl & Patterson  \n",
       "4                     The invoice number is 3195004.  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_df = pd.concat([train_df, val_df, test_df], ignore_index=True)\n",
    "print(all_df.shape)\n",
    "all_df_lst = all_df.to_dict(orient='records')\n",
    "\n",
    "rag_lst = []\n",
    "for record in all_df_lst:\n",
    "    rag_lst.append({\n",
    "        'question': record['question'],\n",
    "        'context': record['context'],\n",
    "        'ground_truth': record['ground_truth']\n",
    "    })\n",
    "\n",
    "rag_df = pd.DataFrame(rag_lst)\n",
    "print(rag_df.shape)\n",
    "rag_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c29cf57e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "90\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'question': 'What is the client company for this financial estimate recap?',\n",
       " 'answer': None,\n",
       " 'id': 'fa226c55-16a2-4d5a-a92f-82038ccef70c',\n",
       " 'gold_titles': 'The client company is P.M. Inc.',\n",
       " 'context': array([\"### Document Type\\nThe document is an advertising financial estimate recap issued by Leo Burnett USA.\\n\\n### Key Details\\n- **Document Identifier:** Estimate Recap - 0001(S)\\n- **Client:** P.M. Inc.\\n- **Date Issued:** June 1, 1985, with a review date of April 12, 1985\\n- **Product/Service:** 42-Dunhill Test\\n- **Period Covered:** June to September 1985\\n- **Description:** 771A - Dunhill Test Cut-In - Ethnic Paint\\n- **Key Financials:**\\n  - **June 1985:** $13,846.84\\n  - **July 1985:** $13,846.84\\n  - **August 1985:** $13,846.84\\n  - **September 1985:** $17,566.17\\n  - **Q3 Total:** $59,106.69\\n- **Gross Change for September 1985:** $3,719.33\\n- **Total Gross Change:** $3,719.33\\n- **Signature:** Document is signed, indicating approval or finalization.\\n\\n### Insights and Observations\\n- The document outlines monthly financial estimates tied to an advertising project specifically for 'Dunhill Test' presumably a campaign for P.M. Inc.\\n- There is a noticeable increase in spending in September 1985, which marked an upsurge of $3,719.33 compared to previous months. This suggests either an expansion in advertising scope or additional costs incurred.\\n- The consistent figures in June to August and the sudden rise in September could indicate strategic planning phases followed by implementation phase which is often more costly.\\n- The presence of a signature in green indicates final approval of the financial estimates, signifying that the presented numbers have been reviewed and accepted by a relevant authority within or associated with Leo Burnett USA. \\n\\nUnderstanding the financial trajectory and approval process highlighted in this document is crucial for tracking budget implementation and effectiveness of the advertising spending over the specified period.\"],\n",
       "       dtype=object)}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def fiqa_to_hotpotqa(record):\n",
    "    return HotPotQAData(\n",
    "        question=record['question'],\n",
    "        gold_titles=record['ground_truth'],\n",
    "        context=record['context']\n",
    "    )\n",
    "\n",
    "fiqa_as_hotpotqa = [fiqa_to_hotpotqa(s) for s in all_df_lst]\n",
    "print(len(fiqa_as_hotpotqa))\n",
    "fiqa_as_hotpotqa[0].to_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9c1fe944",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "30 30 30\n"
     ]
    }
   ],
   "source": [
    "trainset = fiqa_as_hotpotqa[0:len(train_df)]\n",
    "valset = fiqa_as_hotpotqa[len(train_df):len(train_df) + len(val_df)]\n",
    "testset = fiqa_as_hotpotqa[len(train_df) + len(val_df):]\n",
    "print(len(trainset), len(valset), len(testset))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ef96f6e",
   "metadata": {},
   "source": [
    "### AdalFlow Optimization\n",
    "\n",
    "* References\n",
    "  * How to use AdalFlow's GEval and LLM-as-Judge: https://colab.research.google.com/github/SylphAI-Inc/AdalFlow/blob/main/notebooks/evaluation/adalflow_llm_eval.ipynb\n",
    "  * Official evaluation page (I think their user guide is very confusing ðŸ˜…): https://adalflow.sylph.ai/apis/eval/index.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "58a1351e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Context: [\"### Document Type\\nThe document is an advertising financial estimate recap issued by Leo Burnett USA.\\n\\n### Key Details\\n- **Document Identifier:** Estimate Recap - 0001(S)\\n- **Client:** P.M. Inc.\\n- **Date Issued:** June 1, 1985, with a review date of April 12, 1985\\n- **Product/Service:** 42-Dunhill Test\\n- **Period Covered:** June to September 1985\\n- **Description:** 771A - Dunhill Test Cut-In - Ethnic Paint\\n- **Key Financials:**\\n  - **June 1985:** $13,846.84\\n  - **July 1985:** $13,846.84\\n  - **August 1985:** $13,846.84\\n  - **September 1985:** $17,566.17\\n  - **Q3 Total:** $59,106.69\\n- **Gross Change for September 1985:** $3,719.33\\n- **Total Gross Change:** $3,719.33\\n- **Signature:** Document is signed, indicating approval or finalization.\\n\\n### Insights and Observations\\n- The document outlines monthly financial estimates tied to an advertising project specifically for 'Dunhill Test' presumably a campaign for P.M. Inc.\\n- There is a noticeable increase in spending in September 1985, which marked an upsurge of $3,719.33 compared to previous months. This suggests either an expansion in advertising scope or additional costs incurred.\\n- The consistent figures in June to August and the sudden rise in September could indicate strategic planning phases followed by implementation phase which is often more costly.\\n- The presence of a signature in green indicates final approval of the financial estimates, signifying that the presented numbers have been reviewed and accepted by a relevant authority within or associated with Leo Burnett USA. \\n\\nUnderstanding the financial trajectory and approval process highlighted in this document is crucial for tracking budget implementation and effectiveness of the advertising spending over the specified period.\"]\n",
      "Question: What is the client company for this financial estimate recap?\n",
      "Answer: None\n",
      "\n",
      "---\n",
      "Context: ['### Document Type\\nThe image depicts an invoice.\\n\\n### Key Details\\n- **Invoice Header**\\n  - **Company Name:** Copiadora Gouldsvey\\n  - **Address:** 12 Calle Guisqueya, HATO Rey PR 00917-1236\\n  - **Phone/Fax:** (787) 764-1511 / Fax 756-8195\\n  - **Date:** June 10, 1998\\n  - **Invoice Number:** 343419\\n\\n- **Sold To**\\n  - **Customer Name:** Ramos Diaz, Juan A. LCDO.\\n  - **Address:** Ave. De Diego # 339 Suite 901, San Juan, PR, 00909-1711\\n\\n- **Ship To**\\n  - **Customer Name:** Ramos Diaz, Juan A. LCDO.\\n  - **Address:** Ave. De Diego # 339 Suite 901, San Juan, PR, 00909-1711\\n\\n- **Items Sold**\\n  - **Part Number:** 54710\\n  - **Description:** MANUAL, N342. PAGE\\n  - **Quantity:** 1.00\\n  - **Unit Price:** $42.00\\n  - **Extended Price:** $42.00\\n\\n- **Financial Summary**\\n  - **Sales Total:** $42.00\\n  - **Miscellaneous Charges:** $3.00\\n  - **Sales Tax:** $3.83\\n  - **Shipping:** $2.00\\n  - **Invoice Total:** $50.83\\n\\n- **Authorization**\\n  - **Signatures:** Three signatures are present, with \"Juan Letuina\" clearly visible alongside two unreadable ones.\\n\\n### Insights and Observations\\n- The invoice is from 1998, which suggests it may not have any current legal or financial implication but would be significant for historical record-keeping.\\n- Both the billing and shipping addresses are the same, indicating that the purchased item was likely for business use at the same location.\\n- The financial details listed are concise and typical of standard business invoices from this time period, including the segmentation of costs (Sales Total, Miscellaneous Charges, Sales Tax, and Shipping).\\n- The document includes manual item entries, which might have been more prone to error. This necessitates careful archival and cross-referencing for financial accuracy and compliance from historical perspectives.\\n- The presence of multiple signatures suggests validations and approvals which are critical for internal audits and tracking business transactions.\\n\\nThis invoice provides a clear breakdown of sales-related transactions and would serve primarily as a record-keeping tool in financial and business history analyses.']\n",
      "Question: What is the company name and address listed on the invoice?\n",
      "Answer: None\n",
      "\n",
      "---\n",
      "Context: ['### Document Type\\nThis image presents a financial data table likely from a report, specifically `Table 31`, highlighting \"Cash receipts from farm marketings and tobacco\" for the years 1988 to 1997.\\n\\n### Key Details\\n- **Title of Table**: Cash receipts from farm marketings and tobacco, 1988-97\\n- **Data Range**: 1988 to 1997 (annual data)\\n- **Categories Detailed**:\\n  - Livestock and products\\n  - All crops\\n  - Total farm cash receipts\\n- **Cash Receipts (in million dollars)**:\\n  - **1988**: Livestock (79,640), Crops (71,603), Total (151,243)\\n  - **1989**: Livestock (83,918), Crops (76,892), Total (160,810)\\n  - **1990**: Livestock (89,313), Crops (80,356), Total (169,669)\\n  - **1991**: Livestock (85,750), Crops (82,251), Total (167,951)\\n  - **1992**: Livestock (85,596), Crops (85,662), Total (171,346)\\n  - **1993**: Livestock (90,036), Crops (87,102), Total (177,617)\\n  - **1994**: Livestock (88,107), Crops (91,562), Total (180,775)\\n  - **1995**: Livestock (87,004), Crops (100,700), Total (187,704)\\n  - **1996**: Livestock (92,914), Crops (109,425), Total (202,339)\\n  - **1997** (Preliminary): Livestock (93,444), Crops (108,373), Total (201,822)\\n- **Source Annotation**: USDA, possibly sourced from an online USDA briefing room or report archive (as indicated by a URL on the document)\\n\\n### Insights and Observations\\n- **Trend Analysis**: There is a noticeable growth in total annual farm cash receipts over the decade, reflecting increases in both livestock and crop sectors.\\n- **Significant Increase in Crop Sector**: From 1988 to 1996, cash receipts from crops show a significant increase, notably a growth of approximately 52% from 71,603 million dollars in 1988 to 109,425 million dollars in 1996. This might indicate improved crop yields, price increases, or expansion of cultivated areas.\\n- **Stability in Livestock Sector**: The livestock sector shows relatively stable growth with minor fluctuations from year to year.\\n- **Document Quality and Handling**: Trace annotations and scribbles, possibly indicating usage and referencing for reports or presentations. These annotations might reflect document handling and utilization in professional settings.\\n\\nThis table provides valuable historical financial data for analyzing trends in farm marketings and can aid in economic studies, policy-making, or market forecasts regarding the agricultural sector.']\n",
      "Question: What is the total farm cash receipts from 1988 to 1997?\n",
      "Answer: None\n",
      "\n"
     ]
    }
   ],
   "source": [
    "task_desc_str = r\"\"\"Answer questions with short factoid answers.\n",
    "                    You will receive context(contain relevant facts).\n",
    "                    Think step by step.\n",
    "                \"\"\"\n",
    "\n",
    "\n",
    "prompt_template = \"\"\"<START_OF_SYSTEM_PROMPT>\n",
    "{{task_desc_str}}\n",
    "\n",
    "{{output_format_str}}\n",
    "{# Few shot demos #}\n",
    "{% if few_shot_demos is not none %}\n",
    "    Here are some examples:\n",
    "    {{few_shot_demos}}\n",
    "{% endif %}\n",
    "<END_OF_SYSTEM_PROMPT>\n",
    "<START_OF_USER>\n",
    "    Context: {{context}}\n",
    "    Question: {{question}}\n",
    "<END_OF_USER>\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "def format_few_shot_demo(example):\n",
    "    return f\"Context: {example.context}\\nQuestion: {example.question}\\nAnswer: {example.answer}\\n\"\n",
    "\n",
    "few_shot_examples = trainset[:3]  # Use first 3 as demos\n",
    "few_shot_demos_str = \"\\n---\\n\".join([format_few_shot_demo(e) for e in few_shot_examples])\n",
    "print(few_shot_demos_str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b61235db",
   "metadata": {},
   "outputs": [],
   "source": [
    "@dataclass\n",
    "class AnswerData(adal.DataClass):\n",
    "    reasoning: str = field(\n",
    "        metadata={\"desc\": \"The reasoning to produce the answer\"},\n",
    "    )\n",
    "    answer: str = field(\n",
    "        metadata={\"desc\": \"The answer you produced\"},\n",
    "    )\n",
    "\n",
    "    __output_fields__ = [\"reasoning\", \"answer\"]\n",
    "\n",
    "\n",
    "class RAG_AnswerGeneration(adal.Component):\n",
    "    def __init__(self, model_client=None, model_kwargs=None):\n",
    "        super().__init__()\n",
    "\n",
    "        self.llm_parser = adal.DataClassParser(\n",
    "            data_class=AnswerData, return_data_class=True, format_type=\"json\"\n",
    "        )\n",
    "        self.llm = adal.Generator(\n",
    "            model_client=model_client,\n",
    "            model_kwargs=model_kwargs,\n",
    "            prompt_kwargs={\n",
    "                \"task_desc_str\": adal.Parameter(\n",
    "                    data=task_desc_str,\n",
    "                    role_desc=\"\"\"Task description for the language model,\\\n",
    "                            used with the following template: \\\n",
    "                                {{task_desc_str}} \\\n",
    "                                {{output_format_str}}\\\n",
    "                            <START_OF_USER>\n",
    "                                Context: {{context}}\n",
    "                                Question: {{question}}\n",
    "                            <END_OF_USER>\"\"\",\n",
    "                    param_type=adal.ParameterType.PROMPT,\n",
    "                    requires_opt=True,\n",
    "                    instruction_to_backward_engine=\"\"\"You need find the best way\n",
    "                            (where does the right answer come from the context) \n",
    "                            to extract the RIGHT answer from the context.\"\"\",\n",
    "                    instruction_to_optimizer=\"\"\"\n",
    "                        Write ONLY general instructions for answering questions. \n",
    "                        Do NOT include any specific answers, facts, or content from the dataset or any query. \n",
    "                        Do NOT copy or paraphrase any ground-truth answer. \n",
    "                        Your output must be a reusable prompt template, not a response to a specific question.\n",
    "                    \"\"\",\n",
    "                ),\n",
    "                \"output_format_str\": self.llm_parser.get_output_format_str(),\n",
    "            },\n",
    "            template=prompt_template,\n",
    "            output_processors=self.llm_parser,\n",
    "            use_cache=True,\n",
    "        )\n",
    "\n",
    "    def bicall(\n",
    "        self, \n",
    "        question: str, \n",
    "        retrieved_context: str,\n",
    "        id: str = None,\n",
    "        few_shot_demos: str = None\n",
    "    ) -> Union[adal.GeneratorOutput, adal.Parameter]:\n",
    "        \"\"\"\n",
    "            This function is used to call the model for both training and eval mode.\n",
    "        \"\"\"\n",
    "        prompt_kwargs = {\n",
    "            \"context\": retrieved_context,\n",
    "            \"question\": question,\n",
    "        }\n",
    "        if few_shot_demos is not None:\n",
    "            prompt_kwargs[\"few_shot_demos\"] = few_shot_demos\n",
    "        output = self.llm(prompt_kwargs=prompt_kwargs, id=id)\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4575397e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GeneratorOutput(id=None, data=AnswerData(reasoning=\"The context explicitly states that the client for the financial estimate recap is P.M. Inc., which is mentioned under the 'Key Details' section.\", answer='P.M. Inc.'), error=None, usage=CompletionUsage(completion_tokens=51, prompt_tokens=2347, total_tokens=2398), raw_response='```json\\n{\\n    \"reasoning\": \"The context explicitly states that the client for the financial estimate recap is P.M. Inc., which is mentioned under the \\'Key Details\\' section.\",\\n    \"answer\": \"P.M. Inc.\"\\n}\\n```', metadata=None)\n",
      "AnswerData(reasoning='The context explicitly states that the client for the '\n",
      "                     'financial estimate recap is P.M. Inc., which is '\n",
      "                     \"mentioned under the 'Key Details' section.\",\n",
      "           answer='P.M. Inc.')\n"
     ]
    }
   ],
   "source": [
    "# test above RAG_AnswerGeneration logic\n",
    "random_test_data = fiqa_as_hotpotqa[0].to_dict()\n",
    "\n",
    "rag = RAG_AnswerGeneration(**gpt4_model)\n",
    "output = rag.bicall(\n",
    "    question=random_test_data['question'],\n",
    "    retrieved_context=random_test_data['context'],\n",
    "    few_shot_demos=few_shot_demos_str\n",
    ")\n",
    "print(output)\n",
    "pprint(output.data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "901cb9f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "class HotPotQAAdal(adal.AdalComponent):\n",
    "    def __init__(\n",
    "        self,\n",
    "        backward_engine_model_config: Dict | None = None,\n",
    "        teacher_model_config: Dict | None = None,\n",
    "        text_optimizer_model_config: Dict | None = None,\n",
    "        task: adal.Component | None = None,  # initialized task\n",
    "    ):\n",
    "        g_eval = GEvalLLMJudge(default_task=NLGTask.SUMMARIZATION,\n",
    "                                model_kwargs=model_kwargs)\n",
    "        g_evaluator = GEvalJudgeEvaluator(llm_judge=g_eval)\n",
    "        def extract_overall(**kwargs):\n",
    "            if 'input_str'  in kwargs:\n",
    "                match = re.search(r\"Reference Answer:(.*)Predicted Answer:(.*)\", kwargs['input_str'], re.DOTALL)\n",
    "                if match:\n",
    "                    reference = match.group(1).strip()\n",
    "                    predicted = match.group(2).strip()\n",
    "            else:\n",
    "                predicted = kwargs.get(\"y\")\n",
    "                reference = kwargs.get(\"y_gt\")\n",
    "\n",
    "            input_str = f\"Reference Answer: {reference}\\nPredicted Answer: {predicted}\"\n",
    "            return g_evaluator.compute_single_item(input_str)[\"overall\"]\n",
    "\n",
    "        eval_fn = extract_overall\n",
    "        loss_eval_fn = extract_overall\n",
    "\n",
    "        loss_fn = adal.EvalFnToTextLoss(\n",
    "            eval_fn=loss_eval_fn,\n",
    "            eval_fn_desc=\"GEval score\",\n",
    "        )\n",
    "        super().__init__(\n",
    "            task=task,\n",
    "            eval_fn=eval_fn,\n",
    "            loss_eval_fn=loss_eval_fn,\n",
    "            loss_fn=loss_fn,\n",
    "            backward_engine_model_config=backward_engine_model_config,\n",
    "            teacher_model_config=teacher_model_config,\n",
    "            text_optimizer_model_config=text_optimizer_model_config,\n",
    "        )\n",
    "        self.configure_text_optimizer_helper(\n",
    "            model_client=OpenAIClient(),\n",
    "            model_kwargs={\"temperature\": 0.3}\n",
    "        )\n",
    "\n",
    "    def prepare_task(self, sample: HotPotQAData) -> Tuple[Callable[..., Any], Dict]:\n",
    "        task_kwargs = {\n",
    "            \"question\": sample.question,\n",
    "            \"retrieved_context\": sample.context,\n",
    "            \"id\": getattr(sample, \"id\", None),\n",
    "            \"few_shot_demos\": few_shot_demos_str,\n",
    "        }\n",
    "        if self.task.training:\n",
    "            return self.task.forward, task_kwargs\n",
    "        else:\n",
    "            return self.task.call, task_kwargs\n",
    "\n",
    "    def prepare_eval(self, sample: HotPotQAData, y_pred: adal.GeneratorOutput):\n",
    "        y_label = \"\"\n",
    "        if y_pred and y_pred.data and y_pred.data.answer:\n",
    "            y_label = y_pred.data.answer\n",
    "\n",
    "        input_str = (\n",
    "            f\"Reference Answer: {sample.gold_titles}\\n\"\n",
    "            f\"Predicted Answer: {y_label}\"\n",
    "        )\n",
    "\n",
    "        return self.eval_fn, {'input_str': input_str}\n",
    "\n",
    "\n",
    "    def prepare_loss_eval(self, sample: Any, y_pred: Any, *args, **kwargs):\n",
    "        y_label = \"\"\n",
    "        if y_pred and y_pred.data and y_pred.data.answer:\n",
    "            y_label = y_pred.data.answer\n",
    "\n",
    "        input_str = (\n",
    "            f\"Reference Answer: {sample.gold_titles}\\n\"\n",
    "            f\"Predicted Answer: {y_label}\"\n",
    "        )\n",
    "\n",
    "        return self.loss_eval_fn, {'input_str': input_str}\n",
    "\n",
    "\n",
    "    def prepare_loss(self, sample: HotPotQAData, pred: adal.Parameter):\n",
    "        y_gt = adal.Parameter(\n",
    "            name=\"y_gt\",\n",
    "            data=sample.gold_titles,\n",
    "            eval_input=sample.gold_titles,\n",
    "            requires_opt=False,\n",
    "        )\n",
    "        context_param = adal.Parameter(\n",
    "            name=\"context\",\n",
    "            data=sample.context,\n",
    "            eval_input=sample.context,  # you could also stringify it if needed\n",
    "            requires_opt=False,\n",
    "        )\n",
    "\n",
    "        pred.eval_input = (\n",
    "            pred.data.data.answer\n",
    "            if pred.data and pred.data.data and pred.data.data.answer\n",
    "            else \"\"\n",
    "        )\n",
    "        return self.loss_fn, {\n",
    "            \"kwargs\": {\"y\": pred, \"y_gt\": y_gt,\n",
    "                        \"context\": context_param},\n",
    "            \"input\": {\"question\": sample.question,\n",
    "                       \"retrieved_context\": sample.context},\n",
    "            \"gt\": sample.gold_titles,\n",
    "            \"id\": sample.id,\n",
    "        }"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90fef285",
   "metadata": {},
   "source": [
    "<b>Evaluation Only</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b9ae4f16",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generator llm is already registered with jsonl file at C:\\Users\\wuhan\\AppData\\Roaming\\adalflow\\ckpt\\VallinaRAGAdal\\diagnose_train\\llm_call.jsonl\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m2025-07-25 22:44:33 - [adal.py:852:configure_text_optimizer_helper] - Text optimizer configured for 1 parameters. names: [('llm.task_desc_str', 'Answer questions with short factoid answers.\\n                    You will receive context(contain relevant facts).\\n                    Think step by step.\\n                ')]\u001b[0m\n",
      "\u001b[36m2025-07-25 22:44:33 - [trainer.py:227:diagnose] - Checkpoint path: C:\\Users\\wuhan\\AppData\\Roaming\\adalflow\\ckpt\\HotPotQAAdal\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading Data: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 30/30 [00:00<00:00, 1235.68it/s]\n",
      "Predicting: step(0): 0.8661 across 30 samples, Max potential: 0.8661: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 30/30 [00:00<00:00, 67.29it/s]\n",
      "Error loading jsonl file C:\\Users\\wuhan\\AppData\\Roaming\\adalflow\\ckpt\\VallinaRAGAdal\\diagnose_train\\llm_call.jsonl: line contains invalid json: Trailing data (line 46)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Log file C:\\Users\\wuhan\\AppData\\Roaming\\adalflow\\ckpt\\VallinaRAGAdal\\diagnose_train\\llm_call.jsonl is empty. This llm is not called at all.\n",
      "\n",
      "================== DIAGNOSE REPORT ==================\n",
      "\n",
      "âœ” Split: train\n",
      "âœ” Overall accuracy score: 0.87\n",
      "âœ” Log paths:\n",
      "  - Log 1: C:\\Users\\wuhan\\AppData\\Roaming\\adalflow\\ckpt\\VallinaRAGAdal\\diagnose_train\\llm_call.jsonl\n",
      "\n",
      "âœ” Diagnose report completed successfully!\n",
      "\n",
      "=====================================================\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def train_diagnose(model_client, model_kwargs):\n",
    "    task = RAG_AnswerGeneration(\n",
    "        model_client=model_client,\n",
    "        model_kwargs=model_kwargs\n",
    "    )\n",
    "\n",
    "    adal_component = HotPotQAAdal(task=task)\n",
    "    trainer = adal.Trainer(adaltask=adal_component)\n",
    "    trainer.diagnose(dataset=testset, split=\"train\")\n",
    "\n",
    "\n",
    "train_diagnose(**gpt4_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4dc6a710",
   "metadata": {},
   "source": [
    "<b>Training</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "02cbfe73",
   "metadata": {},
   "outputs": [],
   "source": [
    "def regularization_fn(prompt: str, sample: HotPotQAData) -> float:\n",
    "    # Penalize if ground-truth answer appears in the prompt\n",
    "    if sample.answer.strip() in prompt or sample.question.strip() in prompt:\n",
    "        return 1.0  # High penalty\n",
    "    return 0.0     # No penalty\n",
    "\n",
    "optimizer_config = {\n",
    "    \"regularization_fn\": regularization_fn,\n",
    "}\n",
    "\n",
    "def train(\n",
    "    task_model_cliet,\n",
    "    task_model_kwargs,\n",
    "    optimizer_model_config,\n",
    "    backward_engine_model_config,\n",
    "    train_batch_size=4,  # larger batch size is not that effective, probably because of llm's lost in the middle\n",
    "    raw_shots: int = 0,\n",
    "    bootstrap_shots: int = 4,\n",
    "    max_steps=1,\n",
    "    num_workers=4,\n",
    "    strategy=\"constrained\",\n",
    "    optimization_order=\"sequential\",\n",
    "    debug=False,\n",
    "    resume_from_ckpt=None,\n",
    "    exclude_input_fields_from_bootstrap_demos=True,\n",
    "    seed=10,\n",
    "    max_proposals_per_step: int = 5,\n",
    "    disable_backward_gradients: bool = False,\n",
    "    disable_backward: bool = False,\n",
    "):\n",
    "    task = RAG_AnswerGeneration(\n",
    "        model_client=task_model_cliet,\n",
    "        model_kwargs=task_model_kwargs\n",
    "    )\n",
    "\n",
    "    adal_component = HotPotQAAdal(\n",
    "        task=task,\n",
    "        text_optimizer_model_config=optimizer_model_config,\n",
    "        backward_engine_model_config=backward_engine_model_config,\n",
    "    )\n",
    "\n",
    "    trainer = adal.Trainer(\n",
    "        train_batch_size=train_batch_size,\n",
    "        optimizer_config = optimizer_config,\n",
    "        adaltask=adal_component,\n",
    "        strategy=strategy,\n",
    "        max_steps=max_steps,\n",
    "        num_workers=num_workers,\n",
    "        raw_shots=raw_shots,\n",
    "        bootstrap_shots=bootstrap_shots,\n",
    "        debug=debug,\n",
    "        weighted_sampling=False,\n",
    "        optimization_order=optimization_order,\n",
    "        exclude_input_fields_from_bootstrap_demos=exclude_input_fields_from_bootstrap_demos,\n",
    "        max_proposals_per_step=max_proposals_per_step,\n",
    "        text_optimizers_config_kwargs={\"max_past_history\": 5},\n",
    "        disable_backward_gradients=disable_backward_gradients,\n",
    "        disable_backward=disable_backward,\n",
    "    )\n",
    "    trainer.set_random_seed(seed)\n",
    "    print(trainer)\n",
    "\n",
    "    ckpt, _ = trainer.fit(\n",
    "        train_dataset=trainset,\n",
    "        val_dataset=valset,\n",
    "        test_dataset=testset,\n",
    "        resume_from_ckpt=resume_from_ckpt,\n",
    "    )\n",
    "    return ckpt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "192da2a3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-07-25 22:44:52 - [adal.py:852:configure_text_optimizer_helper] - Text optimizer configured for 1 parameters. names: [('llm.task_desc_str', 'Answer questions with short factoid answers.\\n                    You will receive context(contain relevant facts).\\n                    Think step by step.\\n                ')]\n",
      "Trainer(\n",
      "  (adaltask): HotPotQAAdal(\n",
      "    eval_fn: extract_overall, backward_engine: None, backward_engine_model_config: {'model_client': OpenAIClient(), 'model_kwargs': {'model': 'gpt-4.1-nano', 'temperature': 0.7}}, teacher_model_config: None, text_optimizer_model_config: {'model_client': OpenAIClient(), 'model_kwargs': {'model': 'gpt-4.1-nano', 'temperature': 0.7}}\n",
      "    (task): RAG_AnswerGeneration(\n",
      "      (llm_parser): DataClassParser(\n",
      "        data_class=AnswerData, format_type=json,            return_data_class=True, input_fields=[],            output_fields=['reasoning', 'answer']\n",
      "        (_output_processor): JsonParser()\n",
      "        (output_format_prompt): template: Your output should be formatted as a standard JSON instance with the following schema:\n",
      "        ```\n",
      "        {{schema}}\n",
      "        ```\n",
      "        -Make sure to always enclose the JSON output in triple backticks (```). Please do not add anything other than valid JSON output!\n",
      "        -Use double quotes for the keys and string values.\n",
      "        -DO NOT mistaken the \"properties\" and \"type\" in the schema as the actual fields in the JSON output.\n",
      "        -Follow the JSON formatting conventions., prompt_variables: ['schema']\n",
      "      )\n",
      "      (llm): Generator(\n",
      "        model_kwargs={'model': 'gpt-4.1-nano', 'temperature': 0.7}, trainable_prompt_kwargs=['task_desc_str']\n",
      "        (prompt): template: <START_OF_SYSTEM_PROMPT>\n",
      "        {{task_desc_str}}\n",
      "        \n",
      "        {{output_format_str}}\n",
      "        {# Few shot demos #}\n",
      "        {% if few_shot_demos is not none %}\n",
      "            Here are some examples:\n",
      "            {{few_shot_demos}}\n",
      "        {% endif %}\n",
      "        <END_OF_SYSTEM_PROMPT>\n",
      "        <START_OF_USER>\n",
      "            Context: {{context}}\n",
      "            Question: {{question}}\n",
      "        <END_OF_USER>\n",
      "        , prompt_kwargs: {'task_desc_str': 'Answer questions with short factoid answers.\\n                    You will receive context(contain relevant facts).\\n                    Think step by step.\\n                ', 'output_format_str': 'Your output should be formatted as a standard JSON instance with the following schema:\\n```\\n{\\n    \"reasoning\": \"The reasoning to produce the answer (str) (required)\",\\n    \"answer\": \"The answer you produced (str) (required)\"\\n}\\n```\\n-Make sure to always enclose the JSON output in triple backticks (```). Please do not add anything other than valid JSON output!\\n-Use double quotes for the keys and string values.\\n-DO NOT mistaken the \"properties\" and \"type\" in the schema as the actual fields in the JSON output.\\n-Follow the JSON formatting conventions.'}, prompt_variables: ['question', 'few_shot_demos', 'task_desc_str', 'context', 'output_format_str']\n",
      "        (model_client): OpenAIClient()\n",
      "        (output_processors): DataClassParser(\n",
      "          data_class=AnswerData, format_type=json,            return_data_class=True, input_fields=[],            output_fields=['reasoning', 'answer']\n",
      "          (_output_processor): JsonParser()\n",
      "          (output_format_prompt): template: Your output should be formatted as a standard JSON instance with the following schema:\n",
      "          ```\n",
      "          {{schema}}\n",
      "          ```\n",
      "          -Make sure to always enclose the JSON output in triple backticks (```). Please do not add anything other than valid JSON output!\n",
      "          -Use double quotes for the keys and string values.\n",
      "          -DO NOT mistaken the \"properties\" and \"type\" in the schema as the actual fields in the JSON output.\n",
      "          -Follow the JSON formatting conventions., prompt_variables: ['schema']\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (loss_fn): EvalFnToTextLoss()\n",
      "  )\n",
      ")\n",
      "raw_shots: 0, bootstrap_shots: 4\n",
      "No demo parameters found.\n",
      "2025-07-25 22:44:52 - [adal.py:852:configure_text_optimizer_helper] - Text optimizer configured for 1 parameters. names: [('llm.task_desc_str', 'Answer questions with short factoid answers.\\n                    You will receive context(contain relevant facts).\\n                    Think step by step.\\n                ')]\n",
      "No trainable demo params to optimize\n",
      "Backward engine configured for GradComponents\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading Data: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 30/30 [00:00<00:00, 2191.19it/s]\n",
      "Predicting: step(0): 0.885 across 30 samples, Max potential: 0.885: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 30/30 [00:00<00:00, 102.98it/s]  \n",
      "Loading Data: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 30/30 [00:00<00:00, 3472.78it/s]\n",
      "Predicting: step(0): 0.8661 across 30 samples, Max potential: 0.8661: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 30/30 [00:00<00:00, 97.30it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initial validation score: 0.8849999999999999\n",
      "Initial test score: 0.8661111111111112\n",
      "2025-07-25 22:44:53 - [trainer.py:2343:_fit_text_grad_constraint] - Fitting using Textual Gradient Descent with constraints\n",
      "_fit_text_grad_constraint save to C:\\Users\\wuhan\\AppData\\Roaming\\adalflow\\ckpt\\HotPotQAAdal\\constrained_max_steps_12_21fb6_run_1.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch:   0%|          | 0/2 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Step: 1:   0%|          | 0/8 [00:00<?, ?it/s]\n",
      "Loading Data: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:00<00:00, 159.67it/s]\n",
      "Training: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:02<00:00,  1.37it/s]\n",
      "\n",
      "Loading Data: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:00<00:00, 160.82it/s]\n",
      "Calculating Loss: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:02<00:00,  1.70it/s]\n",
      "Evaluating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:00<00:00, 61.82it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Moving batch eval: EvaluationResult(avg_score=0.8708333333333332, per_item_scores=[0.8166666666666667, 1.0, 1.0, 0.6666666666666666], additional_info=None)\n",
      "2025-07-25 22:44:59 - [trainer.py:2172:_text_grad_constraint_propose_step] - Moving batch acc: 0.8708333333333332\n",
      "Moving batch correct size: 4\n",
      "Moving batch error size: 0\n",
      "Subset Error size: 0\n",
      "Subset Correct size: 2\n",
      "Subset score: 0.9083333333333333\n",
      "2025-07-25 22:44:59 - [trainer.py:2178:_text_grad_constraint_propose_step] - Subset batch acc: 0.9083333333333333,0.9083333333333333\n",
      "Subset loss backward...\n",
      "Subset loss backward time: 3.917593002319336\n",
      "Optimizer propose...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Proposing:   0%|          | 0/5 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Proposal: 1\n",
      "2025-07-25 22:45:05 - [trainer.py:2204:_text_grad_constraint_propose_step] - Propose time: 1.6974115371704102\n",
      "New prompts:  [PromptData(id='7c4cfe03-3711-427e-a485-2a8def6f6893', name='llm.task_desc_str', data=\"Answer with the date in MM/DD/YY format, exactly as it appears in the context, for example, '11/30/91'.\", requires_opt=True)]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Loading Data: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:00<00:00, 164.16it/s]\n",
      "Predicting: step(1): 0.8833 across 2 samples, Max potential: 0.8833: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:03<00:00,  1.79s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-07-25 22:45:09 - [trainer.py:2230:_text_grad_constraint_propose_step] - Fail minibatch check, try next proposal: True, 0.8833333333333333 <= 0.9083333333333333\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Proposing:  20%|â–ˆâ–ˆ        | 1/5 [00:05<00:23,  5.85s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Proposal: 2\n",
      "2025-07-25 22:45:12 - [trainer.py:2204:_text_grad_constraint_propose_step] - Propose time: 2.135007381439209\n",
      "New prompts:  [PromptData(id='7c4cfe03-3711-427e-a485-2a8def6f6893', name='llm.task_desc_str', data='Answer questions with short factoid answers. You will receive context (contain relevant facts). Think step by step. Extract dates in MM/DD/YY format, matching the ground truth format precisely.', requires_opt=True)]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Loading Data: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:00<00:00, 112.34it/s]\n",
      "Predicting: step(1): 0.8833 across 2 samples, Max potential: 0.8833: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:01<00:00,  1.17it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-07-25 22:45:14 - [trainer.py:2230:_text_grad_constraint_propose_step] - Fail minibatch check, try next proposal: True, 0.8833333333333333 <= 0.9083333333333333\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Proposing:  40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 2/5 [00:10<00:14,  4.98s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Proposal: 3\n",
      "2025-07-25 22:45:16 - [trainer.py:2204:_text_grad_constraint_propose_step] - Propose time: 2.1667590141296387\n",
      "New prompts:  [PromptData(id='7c4cfe03-3711-427e-a485-2a8def6f6893', name='llm.task_desc_str', data='Answer questions with short factoid answers. For date questions, extract the date in the exact format MM/DD/YY to match ground truth. Think step by step.', requires_opt=True)]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Loading Data: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:00<00:00, 219.19it/s]\n",
      "Predicting: step(1): 0.8833 across 2 samples, Max potential: 0.8833: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:00<00:00,  2.02it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-07-25 22:45:17 - [trainer.py:2230:_text_grad_constraint_propose_step] - Fail minibatch check, try next proposal: True, 0.8833333333333333 <= 0.9083333333333333\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Proposing:  60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 3/5 [00:13<00:08,  4.36s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Proposal: 4\n",
      "2025-07-25 22:45:19 - [trainer.py:2204:_text_grad_constraint_propose_step] - Propose time: 1.8640360832214355\n",
      "New prompts:  [PromptData(id='7c4cfe03-3711-427e-a485-2a8def6f6893', name='llm.task_desc_str', data='Answer questions with short factoid answers. Focus on extracting dates in the exact format MM/DD/YY, matching the ground truth format, and avoid expanding into full date descriptions.', requires_opt=True)]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Loading Data: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:00<00:00, 125.10it/s]\n",
      "Predicting: step(1): 0.8833 across 2 samples, Max potential: 0.8833: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:00<00:00,  2.36it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-07-25 22:45:21 - [trainer.py:2230:_text_grad_constraint_propose_step] - Fail minibatch check, try next proposal: True, 0.8833333333333333 <= 0.9083333333333333\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Proposing:  80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 4/5 [00:17<00:03,  3.91s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Proposal: 5\n",
      "2025-07-25 22:45:22 - [trainer.py:2204:_text_grad_constraint_propose_step] - Propose time: 1.3525142669677734\n",
      "New prompts:  [PromptData(id='7c4cfe03-3711-427e-a485-2a8def6f6893', name='llm.task_desc_str', data='Answer questions with short factoid answers. Think step by step. When extracting dates, ensure they are in the MM/DD/YY format to match the ground truth precisely.', requires_opt=True)]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Loading Data: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:00<00:00, 176.58it/s]\n",
      "Predicting: step(1): 0.8833 across 2 samples, Max potential: 0.8833: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:00<00:00,  2.64it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-07-25 22:45:23 - [trainer.py:2230:_text_grad_constraint_propose_step] - Fail minibatch check, try next proposal: True, 0.8833333333333333 <= 0.9083333333333333\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Proposing: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5/5 [00:19<00:00,  3.94s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No proposal can improve the subset and full set, and val set\n",
      "Saving checkpoint to C:\\Users\\wuhan\\AppData\\Roaming\\adalflow\\ckpt\\HotPotQAAdal\\constrained_max_steps_12_21fb6_run_1.json\n",
      "Done with proposals\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Step: 2:  12%|â–ˆâ–Ž        | 1/8 [00:29<03:29, 29.94s/it]\n",
      "Loading Data: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:00<00:00, 254.66it/s]\n",
      "Training: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:01<00:00,  2.90it/s]\n",
      "\n",
      "Loading Data: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:00<00:00, 206.46it/s]\n",
      "Calculating Loss: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:02<00:00,  1.84it/s]\n",
      "Evaluating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:00<00:00, 58.29it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Moving batch eval: EvaluationResult(avg_score=0.8104166666666667, per_item_scores=[0.8166666666666667, 1.0, 1.0, 0.6666666666666666, 0.4666666666666667, 0.7666666666666667, 0.95, 0.8166666666666667], additional_info=None)\n",
      "2025-07-25 22:45:27 - [trainer.py:2172:_text_grad_constraint_propose_step] - Moving batch acc: 0.8104166666666667\n",
      "Moving batch correct size: 7\n",
      "Moving batch error size: 1\n",
      "Subset Error size: 1\n",
      "Subset Correct size: 2\n",
      "Subset score: 0.6833333333333332\n",
      "2025-07-25 22:45:27 - [trainer.py:2178:_text_grad_constraint_propose_step] - Subset batch acc: 0.6833333333333332,0.6833333333333332\n",
      "Subset loss backward...\n",
      "Subset loss backward time: 6.626593351364136\n",
      "Optimizer propose...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Proposing:   0%|          | 0/5 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Proposal: 1\n",
      "2025-07-25 22:45:36 - [trainer.py:2204:_text_grad_constraint_propose_step] - Propose time: 1.5897667407989502\n",
      "New prompts:  [PromptData(id='7c4cfe03-3711-427e-a485-2a8def6f6893', name='llm.task_desc_str', data='Answer questions with short, fact-based answers. Carefully analyze the provided context to identify the specific detail asked, following the task description schema. Think step by step if necessary to ensure accuracy.', requires_opt=True)]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Loading Data: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:00<00:00, 316.78it/s]\n",
      "Predicting: step(2): 0.6833 across 3 samples, Max potential: 0.6833: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:05<00:00,  1.76s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-07-25 22:45:41 - [trainer.py:2230:_text_grad_constraint_propose_step] - Fail minibatch check, try next proposal: True, 0.6833333333333332 <= 0.6833333333333332\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Proposing:  20%|â–ˆâ–ˆ        | 1/5 [00:07<00:29,  7.31s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Proposal: 2\n",
      "2025-07-25 22:45:44 - [trainer.py:2204:_text_grad_constraint_propose_step] - Propose time: 2.1978111267089844\n",
      "New prompts:  [PromptData(id='7c4cfe03-3711-427e-a485-2a8def6f6893', name='llm.task_desc_str', data='Answer questions with short factoid answers. Explicitly identify key factual details based on the provided schema and context. Think step by step to ensure accuracy.', requires_opt=True)]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Loading Data: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:00<00:00, 140.24it/s]\n",
      "Predicting: step(2): 0.6833 across 3 samples, Max potential: 0.6833: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:07<00:00,  2.51s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-07-25 22:45:52 - [trainer.py:2224:_text_grad_constraint_propose_step] - Pass minibatch check:True, 0.6833333333333335 > 0.6833333333333332\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Loading Data: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 30/30 [00:00<00:00, 794.05it/s]\n",
      "Predicting: step(2): 0.885 across 30 samples, Max potential: 0.885: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 30/30 [00:53<00:00,  1.78s/it]  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimizer revert: 0.8849999999999999 <= 0.8849999999999999\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Proposing:  40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 2/5 [01:11<02:01, 40.59s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Proposal: 3\n",
      "2025-07-25 22:46:47 - [trainer.py:2204:_text_grad_constraint_propose_step] - Propose time: 1.6573173999786377\n",
      "New prompts:  [PromptData(id='7c4cfe03-3711-427e-a485-2a8def6f6893', name='llm.task_desc_str', data='Answer questions with short factoid answers. Explicitly identify key factual details from the context based on the provided schema, thinking step by step to ensure accuracy and relevance.', requires_opt=True)]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Loading Data: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:00<00:00, 155.53it/s]\n",
      "Predicting: step(2): 0.6333 across 3 samples, Max potential: 0.6333: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:03<00:00,  1.03s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-07-25 22:46:50 - [trainer.py:2230:_text_grad_constraint_propose_step] - Fail minibatch check, try next proposal: True, 0.6333333333333333 <= 0.6833333333333332\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Proposing:  60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 3/5 [01:16<00:48, 24.45s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Proposal: 4\n",
      "2025-07-25 22:46:52 - [trainer.py:2204:_text_grad_constraint_propose_step] - Propose time: 1.639535665512085\n",
      "New prompts:  [PromptData(id='7c4cfe03-3711-427e-a485-2a8def6f6893', name='llm.task_desc_str', data='Answer questions with short factoid answers. Think step by step. Use the context to identify key factual details, such as company names, dates, or financial figures, and provide concise answers based on the extracted information.', requires_opt=True)]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Loading Data: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:00<00:00, 166.10it/s]\n",
      "Predicting: step(2): 0.7 across 3 samples, Max potential: 0.7: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:03<00:00,  1.15s/it]      \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-07-25 22:46:56 - [trainer.py:2224:_text_grad_constraint_propose_step] - Pass minibatch check:True, 0.7000000000000001 > 0.6833333333333332\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Loading Data: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 30/30 [00:00<00:00, 697.23it/s]\n",
      "Predicting: step(2): 0.868 across 25 samples, Max potential: 0.89:  83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 25/30 [00:08<00:01,  2.82it/s]   \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimizer revert: 0.864102564102564 <= 0.8849999999999999\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Proposing:  80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 4/5 [01:31<00:20, 20.56s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Proposal: 5\n",
      "2025-07-25 22:47:07 - [trainer.py:2204:_text_grad_constraint_propose_step] - Propose time: 1.6934113502502441\n",
      "New prompts:  [PromptData(id='7c4cfe03-3711-427e-a485-2a8def6f6893', name='llm.task_desc_str', data='Answer questions with short factoid answers. Explicitly identify and extract the specific factual detail asked in the question based on the provided context and schema, ensuring clarity and focus.', requires_opt=True)]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Loading Data: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:00<00:00, 258.53it/s]\n",
      "Predicting: step(2): 0.6389 across 3 samples, Max potential: 0.6389: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:03<00:00,  1.09s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-07-25 22:47:11 - [trainer.py:2230:_text_grad_constraint_propose_step] - Fail minibatch check, try next proposal: True, 0.638888888888889 <= 0.6833333333333332\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Proposing: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5/5 [01:36<00:00, 19.31s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No proposal can improve the subset and full set, and val set\n",
      "Saving checkpoint to C:\\Users\\wuhan\\AppData\\Roaming\\adalflow\\ckpt\\HotPotQAAdal\\constrained_max_steps_12_21fb6_run_1.json\n",
      "Done with proposals\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Step: 3:  25%|â–ˆâ–ˆâ–Œ       | 2/8 [02:17<07:33, 75.55s/it]\n",
      "Loading Data: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:00<00:00, 96.02it/s]\n",
      "Training: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:01<00:00,  3.94it/s]\n",
      "\n",
      "Loading Data: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:00<00:00, 156.82it/s]\n",
      "Calculating Loss: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:01<00:00,  2.31it/s]\n",
      "Evaluating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 12/12 [00:00<00:00, 61.95it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Moving batch eval: EvaluationResult(avg_score=0.8333333333333334, per_item_scores=[0.8166666666666667, 1.0, 1.0, 0.6666666666666666, 0.4666666666666667, 0.7666666666666667, 0.95, 0.8166666666666667, 0.9, 0.9, 0.95, 0.7666666666666667], additional_info=None)\n",
      "2025-07-25 22:47:14 - [trainer.py:2172:_text_grad_constraint_propose_step] - Moving batch acc: 0.8333333333333334\n",
      "Moving batch correct size: 11\n",
      "Moving batch error size: 1\n",
      "Subset Error size: 1\n",
      "Subset Correct size: 2\n",
      "Subset score: 0.7722222222222221\n",
      "2025-07-25 22:47:14 - [trainer.py:2178:_text_grad_constraint_propose_step] - Subset batch acc: 0.7722222222222221,0.7722222222222221\n",
      "Subset loss backward...\n",
      "Subset loss backward time: 7.57248067855835\n",
      "Optimizer propose...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Proposing:   0%|          | 0/5 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Proposal: 1\n",
      "2025-07-25 22:47:24 - [trainer.py:2204:_text_grad_constraint_propose_step] - Propose time: 1.6838011741638184\n",
      "New prompts:  [PromptData(id='7c4cfe03-3711-427e-a485-2a8def6f6893', name='llm.task_desc_str', data='You are 2 steps ahead since your last improvement. Update the variable more rapidly when steps are larger than 3. Ensure the instruction emphasizes batch consistency and quick updates for better performance.', requires_opt=True)]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Loading Data: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:00<00:00, 330.68it/s]\n",
      "Predicting: step(3): 0.7722 across 3 samples, Max potential: 0.7722: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:04<00:00,  1.39s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-07-25 22:47:28 - [trainer.py:2230:_text_grad_constraint_propose_step] - Fail minibatch check, try next proposal: True, 0.7722222222222221 <= 0.7722222222222221\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Proposing:  20%|â–ˆâ–ˆ        | 1/5 [00:06<00:25,  6.34s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Proposal: 2\n",
      "2025-07-25 22:47:30 - [trainer.py:2204:_text_grad_constraint_propose_step] - Propose time: 1.5767874717712402\n",
      "New prompts:  [PromptData(id='7c4cfe03-3711-427e-a485-2a8def6f6893', name='llm.task_desc_str', data='Answer questions with short factoid answers. Receive context containing relevant facts. Think step by step. When the number of steps exceeds 3, update the answer more rapidly to ensure efficiency. Maintain consistency across the entire batch to improve performance.', requires_opt=True)]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Loading Data: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:00<00:00, 89.15it/s]\n",
      "Predicting: step(3): 0.8222 across 3 samples, Max potential: 0.8222: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:02<00:00,  1.06it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-07-25 22:47:33 - [trainer.py:2224:_text_grad_constraint_propose_step] - Pass minibatch check:True, 0.8222222222222223 > 0.7722222222222221\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Loading Data: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 30/30 [00:00<00:00, 795.21it/s]\n",
      "Predicting: step(3): 0.868 across 25 samples, Max potential: 0.89:  83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 25/30 [00:07<00:01,  3.37it/s]   \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimizer revert: 0.864102564102564 <= 0.8849999999999999\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Proposing:  40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 2/5 [00:18<00:29,  9.95s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Proposal: 3\n",
      "2025-07-25 22:47:43 - [trainer.py:2204:_text_grad_constraint_propose_step] - Propose time: 1.484738826751709\n",
      "New prompts:  [PromptData(id='7c4cfe03-3711-427e-a485-2a8def6f6893', name='llm.task_desc_str', data='Answer questions with short factoid answers. Think step by step. When processing multiple items or batches, update the instructions to specify rapid adaptation when steps are larger than 3, and ensure batch consistency.', requires_opt=True)]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Loading Data: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:00<00:00, 163.40it/s]\n",
      "Predicting: step(3): 0.7278 across 3 samples, Max potential: 0.7278: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:04<00:00,  1.35s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-07-25 22:47:47 - [trainer.py:2230:_text_grad_constraint_propose_step] - Fail minibatch check, try next proposal: True, 0.7277777777777779 <= 0.7722222222222221\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Proposing:  60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 3/5 [00:24<00:16,  8.17s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Proposal: 4\n",
      "2025-07-25 22:47:49 - [trainer.py:2204:_text_grad_constraint_propose_step] - Propose time: 1.4734129905700684\n",
      "New prompts:  [PromptData(id='7c4cfe03-3711-427e-a485-2a8def6f6893', name='llm.task_desc_str', data='Set context and role as a task-specific assistant that updates task description more rapidly when steps > 3, and ensure batch processing consistency.', requires_opt=True)]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Loading Data: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:00<00:00, 174.85it/s]\n",
      "Predicting: step(3): 0.7444 across 3 samples, Max potential: 0.7444: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:04<00:00,  1.41s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-07-25 22:47:53 - [trainer.py:2230:_text_grad_constraint_propose_step] - Fail minibatch check, try next proposal: True, 0.7444444444444445 <= 0.7722222222222221\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Proposing:  80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 4/5 [00:31<00:07,  7.43s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Proposal: 5\n",
      "2025-07-25 22:47:55 - [trainer.py:2204:_text_grad_constraint_propose_step] - Propose time: 1.2495477199554443\n",
      "New prompts:  [PromptData(id='7c4cfe03-3711-427e-a485-2a8def6f6893', name='llm.task_desc_str', data='Answer questions with short factoid answers. Think step by step. When step count exceeds 3, update the response more rapidly. Ensure consistency across batch inputs.', requires_opt=True)]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Loading Data: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:00<00:00, 169.75it/s]\n",
      "Predicting: step(3): 0.7389 across 3 samples, Max potential: 0.7389: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:02<00:00,  1.24it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-07-25 22:47:57 - [trainer.py:2230:_text_grad_constraint_propose_step] - Fail minibatch check, try next proposal: True, 0.7388888888888889 <= 0.7722222222222221\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Proposing: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5/5 [00:35<00:00,  7.07s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No proposal can improve the subset and full set, and val set\n",
      "Saving checkpoint to C:\\Users\\wuhan\\AppData\\Roaming\\adalflow\\ckpt\\HotPotQAAdal\\constrained_max_steps_12_21fb6_run_1.json\n",
      "Done with proposals\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Step: 4:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [03:04<05:12, 62.42s/it]\n",
      "Loading Data: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:00<00:00, 92.79it/s]\n",
      "Training: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:00<00:00,  5.01it/s]\n",
      "\n",
      "Loading Data: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:00<00:00, 71.13it/s]\n",
      "Calculating Loss: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:01<00:00,  2.57it/s]\n",
      "Evaluating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 16/16 [00:00<00:00, 67.84it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Moving batch eval: EvaluationResult(avg_score=0.8385416666666667, per_item_scores=[0.8166666666666667, 1.0, 1.0, 0.6666666666666666, 0.4666666666666667, 0.7666666666666667, 0.95, 0.8166666666666667, 0.9, 0.9, 0.95, 0.7666666666666667, 0.7000000000000001, 1.0, 0.7166666666666667, 1.0], additional_info=None)\n",
      "2025-07-25 22:48:01 - [trainer.py:2172:_text_grad_constraint_propose_step] - Moving batch acc: 0.8385416666666667\n",
      "Moving batch correct size: 15\n",
      "Moving batch error size: 1\n",
      "Subset Error size: 1\n",
      "Subset Correct size: 2\n",
      "Subset score: 0.6444444444444445\n",
      "2025-07-25 22:48:01 - [trainer.py:2178:_text_grad_constraint_propose_step] - Subset batch acc: 0.6444444444444445,0.6444444444444445\n",
      "Subset loss backward...\n",
      "Subset loss backward time: 8.017658710479736\n",
      "Optimizer propose...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Proposing:   0%|          | 0/5 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Proposal: 1\n",
      "2025-07-25 22:48:11 - [trainer.py:2204:_text_grad_constraint_propose_step] - Propose time: 2.521388053894043\n",
      "New prompts:  [PromptData(id='7c4cfe03-3711-427e-a485-2a8def6f6893', name='llm.task_desc_str', data='Answer questions with short factoid answers. You will receive context(contain relevant facts). Think step by step. The context states the total budget for 1997 as $1,000,000, which should be the answer.', requires_opt=True)]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Loading Data: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:00<00:00, 158.41it/s]\n",
      "Predicting: step(4): 0.5722 across 3 samples, Max potential: 0.5722: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:07<00:00,  2.59s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-07-25 22:48:20 - [trainer.py:2230:_text_grad_constraint_propose_step] - Fail minibatch check, try next proposal: True, 0.5722222222222223 <= 0.6444444444444445\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Proposing:  20%|â–ˆâ–ˆ        | 1/5 [00:10<00:43, 10.82s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Proposal: 2\n",
      "2025-07-25 22:48:22 - [trainer.py:2204:_text_grad_constraint_propose_step] - Propose time: 2.6412415504455566\n",
      "New prompts:  [PromptData(id='7c4cfe03-3711-427e-a485-2a8def6f6893', name='llm.task_desc_str', data=\"Answer questions with short factoid answers. The context clearly states the total budget for 1997 as $1,000,000, so the answer is '$1,000,000'.\", requires_opt=True)]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Loading Data: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:00<00:00, 143.94it/s]\n",
      "Predicting: step(4): 0.6333 across 3 samples, Max potential: 0.6333: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:04<00:00,  1.39s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-07-25 22:48:27 - [trainer.py:2230:_text_grad_constraint_propose_step] - Fail minibatch check, try next proposal: True, 0.6333333333333333 <= 0.6444444444444445\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Proposing:  40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 2/5 [00:18<00:26,  8.74s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Proposal: 3\n",
      "2025-07-25 22:48:28 - [trainer.py:2204:_text_grad_constraint_propose_step] - Propose time: 1.2817771434783936\n",
      "New prompts:  [PromptData(id='7c4cfe03-3711-427e-a485-2a8def6f6893', name='llm.task_desc_str', data='Answer the question by directly citing the total budget for 1997 as given in the context, which is $1,000,000.', requires_opt=True)]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Loading Data: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:00<00:00, 182.95it/s]\n",
      "Predicting: step(4): 0.7111 across 3 samples, Max potential: 0.7111: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:06<00:00,  2.01s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-07-25 22:48:35 - [trainer.py:2224:_text_grad_constraint_propose_step] - Pass minibatch check:True, 0.7111111111111111 > 0.6444444444444445\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Loading Data: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 30/30 [00:00<00:00, 992.38it/s]\n",
      "Predicting: step(4): 0.8718 across 26 samples, Max potential: 0.8889:  87%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 26/30 [00:46<00:07,  1.79s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimizer revert: 0.8716049382716049 <= 0.8849999999999999\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Proposing:  60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 3/5 [01:12<00:59, 29.62s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Proposal: 4\n",
      "2025-07-25 22:49:23 - [trainer.py:2204:_text_grad_constraint_propose_step] - Propose time: 1.1927495002746582\n",
      "New prompts:  [PromptData(id='7c4cfe03-3711-427e-a485-2a8def6f6893', name='llm.task_desc_str', data='Answer questions with short factoid answers. The context contains the relevant facts, including the total budget for 1997 being $1,000,000. The instruction emphasizes extracting this directly from the context.', requires_opt=True)]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Loading Data: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:00<00:00, 101.05it/s]\n",
      "Predicting: step(4): 0.6667 across 3 samples, Max potential: 0.6667: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:06<00:00,  2.15s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-07-25 22:49:29 - [trainer.py:2224:_text_grad_constraint_propose_step] - Pass minibatch check:True, 0.6666666666666666 > 0.6444444444444445\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Loading Data: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 30/30 [00:00<00:00, 1302.23it/s]\n",
      "Predicting: step(4): 0.8712 across 26 samples, Max potential: 0.8883:  87%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 26/30 [00:15<00:02,  1.73it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimizer revert: 0.8709876543209876 <= 0.8849999999999999\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Proposing:  80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 4/5 [01:35<00:27, 27.11s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Proposal: 5\n",
      "2025-07-25 22:49:46 - [trainer.py:2204:_text_grad_constraint_propose_step] - Propose time: 1.4708850383758545\n",
      "New prompts:  [PromptData(id='7c4cfe03-3711-427e-a485-2a8def6f6893', name='llm.task_desc_str', data='Answer: $1,000,000', requires_opt=True)]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Loading Data: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:00<00:00, 124.07it/s]\n",
      "Predicting: step(4): 0.6667 across 3 samples, Max potential: 0.6667: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:02<00:00,  1.00it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-07-25 22:49:50 - [trainer.py:2224:_text_grad_constraint_propose_step] - Pass minibatch check:True, 0.6666666666666666 > 0.6444444444444445\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Loading Data: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 30/30 [00:00<00:00, 536.90it/s]\n",
      "Predicting: step(4): 0.8102 across 18 samples, Max potential: 0.8861:  60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 18/30 [00:08<00:05,  2.18it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimizer revert: 0.8052631578947368 <= 0.8849999999999999\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Proposing: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5/5 [01:49<00:00, 21.85s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No proposal can improve the subset and full set, and val set\n",
      "Saving checkpoint to C:\\Users\\wuhan\\AppData\\Roaming\\adalflow\\ckpt\\HotPotQAAdal\\constrained_max_steps_12_21fb6_run_1.json\n",
      "Done with proposals\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Step: 5:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 4/8 [05:04<05:41, 85.39s/it]\n",
      "Loading Data: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:00<00:00, 132.53it/s]\n",
      "Training: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:01<00:00,  3.91it/s]\n",
      "\n",
      "Loading Data: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:00<00:00, 177.28it/s]\n",
      "Calculating Loss: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:01<00:00,  2.16it/s]\n",
      "Evaluating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 20/20 [00:00<00:00, 70.72it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Moving batch eval: EvaluationResult(avg_score=0.8283333333333334, per_item_scores=[0.8166666666666667, 1.0, 1.0, 0.6666666666666666, 0.4666666666666667, 0.7666666666666667, 0.95, 0.8166666666666667, 0.9, 0.9, 0.95, 0.7666666666666667, 0.7000000000000001, 1.0, 0.7166666666666667, 1.0, 0.8666666666666667, 0.95, 1.0, 0.33333333333333337], additional_info=None)\n",
      "2025-07-25 22:50:02 - [trainer.py:2172:_text_grad_constraint_propose_step] - Moving batch acc: 0.8283333333333334\n",
      "Moving batch correct size: 18\n",
      "Moving batch error size: 2\n",
      "Subset Error size: 2\n",
      "Subset Correct size: 2\n",
      "Subset score: 0.6875\n",
      "2025-07-25 22:50:02 - [trainer.py:2178:_text_grad_constraint_propose_step] - Subset batch acc: 0.6875,0.6875\n",
      "Subset loss backward...\n",
      "Subset loss backward time: 5.847296714782715\n",
      "Optimizer propose...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Proposing:   0%|          | 0/5 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Proposal: 1\n",
      "2025-07-25 22:50:10 - [trainer.py:2204:_text_grad_constraint_propose_step] - Propose time: 1.9877266883850098\n",
      "New prompts:  [PromptData(id='7c4cfe03-3711-427e-a485-2a8def6f6893', name='llm.task_desc_str', data='Answer questions with short factoid answers. You will receive context (contain relevant facts). Think step by step. Focus on extracting the specific detail requested (e.g., invoice number). Provide the answer as a short string. Do not include any extraneous information.', requires_opt=True)]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Loading Data: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:00<00:00, 163.72it/s]\n",
      "Predicting: step(5): 0.75 across 4 samples, Max potential: 0.75: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:03<00:00,  1.21it/s]    \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-07-25 22:50:13 - [trainer.py:2224:_text_grad_constraint_propose_step] - Pass minibatch check:True, 0.75 > 0.6875\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Loading Data: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 30/30 [00:00<00:00, 591.69it/s]\n",
      "Predicting: step(5): 0.8712 across 26 samples, Max potential: 0.8883:  87%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 26/30 [00:06<00:01,  3.84it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimizer revert: 0.8709876543209876 <= 0.8849999999999999\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Proposing:  20%|â–ˆâ–ˆ        | 1/5 [00:12<00:51, 12.78s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Proposal: 2\n",
      "2025-07-25 22:50:22 - [trainer.py:2204:_text_grad_constraint_propose_step] - Propose time: 1.688164234161377\n",
      "New prompts:  [PromptData(id='7c4cfe03-3711-427e-a485-2a8def6f6893', name='llm.task_desc_str', data='Answer questions with short factoid answers. Clearly extract the specified key detail (e.g., invoice number, company name, address) from the context. Think step by step and ensure the answer is precise and accurate.', requires_opt=True)]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Loading Data: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:00<00:00, 135.36it/s]\n",
      "Predicting: step(5): 0.8417 across 4 samples, Max potential: 0.8417: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:04<00:00,  1.04s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-07-25 22:50:27 - [trainer.py:2224:_text_grad_constraint_propose_step] - Pass minibatch check:True, 0.8416666666666666 > 0.6875\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Loading Data: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 30/30 [00:00<00:00, 846.80it/s]\n",
      "Predicting: step(5): 0.8728 across 27 samples, Max potential: 0.8856:  90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 27/30 [00:10<00:01,  2.63it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimizer revert: 0.8726190476190476 <= 0.8849999999999999\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Proposing:  40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 2/5 [00:29<00:45, 15.13s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Proposal: 3\n",
      "2025-07-25 22:50:41 - [trainer.py:2204:_text_grad_constraint_propose_step] - Propose time: 3.314664363861084\n",
      "New prompts:  [PromptData(id='7c4cfe03-3711-427e-a485-2a8def6f6893', name='llm.task_desc_str', data='Answer questions with short factoid answers. The question asks for the invoice number. Find and extract the invoice number explicitly provided in the context, ensuring the answer is correct and directly sourced from the context details.', requires_opt=True)]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Loading Data: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:00<00:00, 146.01it/s]\n",
      "Predicting: step(5): 0.6917 across 4 samples, Max potential: 0.6917: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:04<00:00,  1.21s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-07-25 22:50:46 - [trainer.py:2224:_text_grad_constraint_propose_step] - Pass minibatch check:True, 0.6916666666666667 > 0.6875\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Loading Data: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 30/30 [00:00<00:00, 1185.08it/s]\n",
      "Predicting: step(5): 0.85 across 22 samples, Max potential: 0.89:  73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 22/30 [00:08<00:03,  2.45it/s]    \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimizer revert: 0.8485507246376811 <= 0.8849999999999999\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Proposing:  60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 3/5 [00:47<00:32, 16.33s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Proposal: 4\n",
      "2025-07-25 22:50:57 - [trainer.py:2204:_text_grad_constraint_propose_step] - Propose time: 1.7629084587097168\n",
      "New prompts:  [PromptData(id='7c4cfe03-3711-427e-a485-2a8def6f6893', name='llm.task_desc_str', data=\"Answer questions with short factoid answers. You will receive context(contain relevant facts). Think step by step. Explicitly locate and extract the invoice number from the context, which is given as '3195004'. Ensure the answer is the exact invoice number without additional words.\", requires_opt=True)]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Loading Data: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:00<00:00, 145.98it/s]\n",
      "Predicting: step(5): 0.7958 across 4 samples, Max potential: 0.7958: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:05<00:00,  1.40s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-07-25 22:51:03 - [trainer.py:2224:_text_grad_constraint_propose_step] - Pass minibatch check:True, 0.7958333333333334 > 0.6875\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Loading Data: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 30/30 [00:00<00:00, 1612.95it/s]\n",
      "Predicting: step(5): 0.8558 across 20 samples, Max potential: 0.9039:  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 20/30 [00:07<00:03,  2.69it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimizer revert: 0.8261904761904761 <= 0.8849999999999999\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Proposing:  80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 4/5 [01:02<00:15, 15.95s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Proposal: 5\n",
      "2025-07-25 22:51:12 - [trainer.py:2204:_text_grad_constraint_propose_step] - Propose time: 1.846574306488037\n",
      "New prompts:  [PromptData(id='7c4cfe03-3711-427e-a485-2a8def6f6893', name='llm.task_desc_str', data=\"Answer questions with short factoid answers. The key detail to extract is the invoice number, which is explicitly provided in the context as '3195004'. Focus on locating and extracting this exact detail directly from the context for accurate response.\", requires_opt=True)]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Loading Data: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:00<00:00, 162.95it/s]\n",
      "Predicting: step(5): 0.8542 across 4 samples, Max potential: 0.8542: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:02<00:00,  1.52it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-07-25 22:51:15 - [trainer.py:2224:_text_grad_constraint_propose_step] - Pass minibatch check:True, 0.8541666666666667 > 0.6875\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Loading Data: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 30/30 [00:00<00:00, 899.43it/s]\n",
      "Predicting: step(5): 0.8699 across 26 samples, Max potential: 0.8872:  87%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 26/30 [00:07<00:01,  3.61it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimizer revert: 0.8697530864197531 <= 0.8849999999999999\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Proposing: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5/5 [01:15<00:00, 15.02s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No proposal can improve the subset and full set, and val set\n",
      "Saving checkpoint to C:\\Users\\wuhan\\AppData\\Roaming\\adalflow\\ckpt\\HotPotQAAdal\\constrained_max_steps_12_21fb6_run_1.json\n",
      "Done with proposals\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Step: 6:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [06:29<04:15, 85.14s/it]\n",
      "Loading Data: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:00<00:00, 117.09it/s]\n",
      "Training: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:01<00:00,  2.70it/s]\n",
      "\n",
      "Loading Data: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:00<00:00, 219.55it/s]\n",
      "Calculating Loss: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:02<00:00,  1.86it/s]\n",
      "Evaluating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 24/24 [00:00<00:00, 60.99it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Moving batch eval: EvaluationResult(avg_score=0.8416666666666667, per_item_scores=[0.8166666666666667, 1.0, 1.0, 0.6666666666666666, 0.4666666666666667, 0.7666666666666667, 0.95, 0.8166666666666667, 0.9, 0.9, 0.95, 0.7666666666666667, 0.7000000000000001, 1.0, 0.7166666666666667, 1.0, 0.8666666666666667, 0.95, 1.0, 0.33333333333333337, 0.95, 0.8166666666666667, 0.8666666666666667, 1.0], additional_info=None)\n",
      "2025-07-25 22:51:27 - [trainer.py:2172:_text_grad_constraint_propose_step] - Moving batch acc: 0.8216666666666667\n",
      "Moving batch correct size: 18\n",
      "Moving batch error size: 2\n",
      "Subset Error size: 2\n",
      "Subset Correct size: 2\n",
      "Subset score: 0.6625000000000001\n",
      "2025-07-25 22:51:27 - [trainer.py:2178:_text_grad_constraint_propose_step] - Subset batch acc: 0.6625000000000001,0.6625000000000001\n",
      "Subset loss backward...\n",
      "Subset loss backward time: 12.448458909988403\n",
      "Optimizer propose...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Proposing:   0%|          | 0/5 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Proposal: 1\n",
      "2025-07-25 22:51:45 - [trainer.py:2204:_text_grad_constraint_propose_step] - Propose time: 5.06087851524353\n",
      "New prompts:  [PromptData(id='7c4cfe03-3711-427e-a485-2a8def6f6893', name='llm.task_desc_str', data='Answer questions with short factoid answers. You will receive context (contain relevant facts). Think step by step. Focus on extracting the most relevant factoid directly answering the question. Do not include explanations or additional commentary. Ensure the answer is concise, accurate, and based solely on the provided context.', requires_opt=True)]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Loading Data: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:00<00:00, 116.09it/s]\n",
      "Predicting: step(6): 0.8083 across 4 samples, Max potential: 0.8083: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:38<00:00,  9.54s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-07-25 22:52:24 - [trainer.py:2224:_text_grad_constraint_propose_step] - Pass minibatch check:True, 0.8083333333333333 > 0.6625000000000001\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Loading Data: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 30/30 [00:00<00:00, 1263.40it/s]\n",
      "Predicting: step(6): 0.8883 across 30 samples, Max potential: 0.8883: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 30/30 [00:07<00:00,  3.94it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimizer step: 0.8883333333333333 > 0.8849999999999999\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Proposing:   0%|          | 0/5 [00:51<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving checkpoint to C:\\Users\\wuhan\\AppData\\Roaming\\adalflow\\ckpt\\HotPotQAAdal\\constrained_max_steps_12_21fb6_run_1.json\n",
      "Done with proposals\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Step: 7:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 6/8 [07:38<02:39, 79.68s/it]\n",
      "Loading Data: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:00<00:00, 175.24it/s]\n",
      "Training: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:00<00:00,  4.18it/s]\n",
      "\n",
      "Loading Data: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:00<00:00, 203.74it/s]\n",
      "Calculating Loss: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:00<00:00, 45.40it/s]\n",
      "Evaluating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:00<00:00, 71.40it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Moving batch eval: EvaluationResult(avg_score=0.8208333333333333, per_item_scores=[0.5166666666666666, 0.8166666666666667, 0.95, 1.0], additional_info=None)\n",
      "2025-07-25 22:52:33 - [trainer.py:2172:_text_grad_constraint_propose_step] - Moving batch acc: 0.8208333333333333\n",
      "Moving batch correct size: 4\n",
      "Moving batch error size: 0\n",
      "Subset Error size: 0\n",
      "Subset Correct size: 2\n",
      "Subset score: 0.6666666666666666\n",
      "2025-07-25 22:52:34 - [trainer.py:2178:_text_grad_constraint_propose_step] - Subset batch acc: 0.6666666666666666,0.6666666666666666\n",
      "Subset loss backward...\n",
      "Subset loss backward time: 7.268210411071777\n",
      "Optimizer propose...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Proposing:   0%|          | 0/5 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Proposal: 1\n",
      "2025-07-25 22:52:43 - [trainer.py:2204:_text_grad_constraint_propose_step] - Propose time: 1.4711787700653076\n",
      "New prompts:  [PromptData(id='7c4cfe03-3711-427e-a485-2a8def6f6893', name='llm.task_desc_str', data='Answer the question based on the departments explicitly listed in the provided report content. Extract the department names directly from the report and ensure the answer is concise and based solely on this information.', requires_opt=True)]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Loading Data: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:00<00:00, 196.35it/s]\n",
      "Predicting: step(7): 0.7917 across 2 samples, Max potential: 0.7917: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:10<00:00,  5.48s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-07-25 22:52:54 - [trainer.py:2224:_text_grad_constraint_propose_step] - Pass minibatch check:True, 0.7916666666666666 > 0.6666666666666666\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Loading Data: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 30/30 [00:00<00:00, 655.75it/s]\n",
      "Predicting: step(7): 0.872 across 25 samples, Max potential: 0.8933:  83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 25/30 [00:15<00:03,  1.65it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimizer revert: 0.8698717948717949 <= 0.8883333333333333\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Proposing:  20%|â–ˆâ–ˆ        | 1/5 [00:28<01:52, 28.25s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Proposal: 2\n",
      "2025-07-25 22:53:11 - [trainer.py:2204:_text_grad_constraint_propose_step] - Propose time: 1.5625677108764648\n",
      "New prompts:  [PromptData(id='7c4cfe03-3711-427e-a485-2a8def6f6893', name='llm.task_desc_str', data=\"Answer the question based solely on the report content, explicitly stating the departments listed within the provided report. Keep the answer concise and directly related to the context, ensuring the model references the report's department list correctly.\", requires_opt=True)]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Loading Data: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:00<00:00, 180.17it/s]\n",
      "Predicting: step(7): 0.6667 across 2 samples, Max potential: 0.6667: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:00<00:00,  2.30it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-07-25 22:53:12 - [trainer.py:2230:_text_grad_constraint_propose_step] - Fail minibatch check, try next proposal: True, 0.6666666666666666 <= 0.6666666666666666\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Proposing:  40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 2/5 [00:31<00:40, 13.39s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Proposal: 3\n",
      "2025-07-25 22:53:14 - [trainer.py:2204:_text_grad_constraint_propose_step] - Propose time: 1.713730812072754\n",
      "New prompts:  [PromptData(id='7c4cfe03-3711-427e-a485-2a8def6f6893', name='llm.task_desc_str', data='Answer questions with short, fact-based answers strictly supported by the provided context. Focus on extracting the most relevant factoid directly answering the question. Do not include explanations or additional commentary. Ensure the answer is concise, accurate, and based solely on the input information.', requires_opt=True)]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Loading Data: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:00<00:00, 166.13it/s]\n",
      "Predicting: step(7): 0.6667 across 2 samples, Max potential: 0.6667: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:00<00:00,  2.86it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-07-25 22:53:15 - [trainer.py:2230:_text_grad_constraint_propose_step] - Fail minibatch check, try next proposal: True, 0.6666666666666666 <= 0.6666666666666666\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Proposing:  60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 3/5 [00:34<00:17,  8.60s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Proposal: 4\n",
      "2025-07-25 22:53:17 - [trainer.py:2204:_text_grad_constraint_propose_step] - Propose time: 2.0481655597686768\n",
      "New prompts:  [PromptData(id='7c4cfe03-3711-427e-a485-2a8def6f6893', name='llm.task_desc_str', data='Answer questions with short, fact-based answers. You will receive context containing relevant facts. Think step by step. Focus on extracting the most relevant factoid directly answering the question. Do not include explanations or additional commentary. Ensure the answer is concise, accurate, and based solely on the provided context. Clearly state that the list of departments or entities must be directly supported by the report content, and answers should be extracted from that source.', requires_opt=True)]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Loading Data: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:00<00:00, 180.17it/s]\n",
      "Predicting: step(7): 0.6667 across 2 samples, Max potential: 0.6667: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:01<00:00,  1.85it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-07-25 22:53:19 - [trainer.py:2230:_text_grad_constraint_propose_step] - Fail minibatch check, try next proposal: True, 0.6666666666666666 <= 0.6666666666666666\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Proposing:  80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 4/5 [00:37<00:06,  6.65s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Proposal: 5\n",
      "2025-07-25 22:53:21 - [trainer.py:2204:_text_grad_constraint_propose_step] - Propose time: 1.6571128368377686\n",
      "New prompts:  [PromptData(id='7c4cfe03-3711-427e-a485-2a8def6f6893', name='llm.task_desc_str', data='Answer the question based solely on the provided report content, explicitly stating that the listed departments are derived from this content. Ensure the answer is concise, specific, and directly supported by the context.', requires_opt=True)]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Loading Data: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:00<00:00, 171.86it/s]\n",
      "Predicting: step(7): 0.6667 across 2 samples, Max potential: 0.6667: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:00<00:00,  2.47it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-07-25 22:53:22 - [trainer.py:2230:_text_grad_constraint_propose_step] - Fail minibatch check, try next proposal: True, 0.6666666666666666 <= 0.6666666666666666\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Proposing: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5/5 [00:40<00:00,  8.16s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No proposal can improve the subset and full set, and val set\n",
      "Saving checkpoint to C:\\Users\\wuhan\\AppData\\Roaming\\adalflow\\ckpt\\HotPotQAAdal\\constrained_max_steps_12_21fb6_run_1.json\n",
      "Done with proposals\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Step: 8:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [08:28<01:09, 69.97s/it]\n",
      "Loading Data: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:00<00:00, 218.87it/s]\n",
      "Training: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:00<00:00,  2.28it/s]\n",
      "\n",
      "Loading Data: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:00<00:00, 155.80it/s]\n",
      "Calculating Loss: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:01<00:00,  1.17it/s]\n",
      "Evaluating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 6/6 [00:00<00:00, 50.09it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Moving batch eval: EvaluationResult(avg_score=0.85, per_item_scores=[0.5166666666666666, 0.8166666666666667, 0.95, 1.0, 1.0, 0.8166666666666667], additional_info=None)\n",
      "2025-07-25 22:53:25 - [trainer.py:2172:_text_grad_constraint_propose_step] - Moving batch acc: 0.85\n",
      "Moving batch correct size: 6\n",
      "Moving batch error size: 0\n",
      "Subset Error size: 0\n",
      "Subset Correct size: 2\n",
      "Subset score: 0.9083333333333333\n",
      "2025-07-25 22:53:25 - [trainer.py:2178:_text_grad_constraint_propose_step] - Subset batch acc: 0.9083333333333333,0.9083333333333333\n",
      "Subset loss backward...\n",
      "Subset loss backward time: 2.8919906616210938\n",
      "Optimizer propose...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Proposing:   0%|          | 0/5 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Proposal: 1\n",
      "2025-07-25 22:53:30 - [trainer.py:2204:_text_grad_constraint_propose_step] - Propose time: 2.085531711578369\n",
      "New prompts:  [PromptData(id='7c4cfe03-3711-427e-a485-2a8def6f6893', name='llm.task_desc_str', data=\"Answer questions with short factoid answers. Always locate the relevant label (e.g., 'Customer No.', 'Invoice Issuer', 'Company Name') within the provided context and extract the associated value directly from the same section. Focus on extracting the most relevant factoid that directly answers the question, without additional commentary. Ensure the answer is concise, accurate, and solely based on the provided context.\", requires_opt=True)]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Loading Data: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:00<00:00, 202.94it/s]\n",
      "Predicting: step(8): 0.9083 across 2 samples, Max potential: 0.9083: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:00<00:00,  2.40it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-07-25 22:53:32 - [trainer.py:2230:_text_grad_constraint_propose_step] - Fail minibatch check, try next proposal: True, 0.9083333333333333 <= 0.9083333333333333\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Proposing:  20%|â–ˆâ–ˆ        | 1/5 [00:03<00:13,  3.42s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Proposal: 2\n",
      "2025-07-25 22:53:34 - [trainer.py:2204:_text_grad_constraint_propose_step] - Propose time: 2.0956954956054688\n",
      "New prompts:  [PromptData(id='7c4cfe03-3711-427e-a485-2a8def6f6893', name='llm.task_desc_str', data=\"Answer questions with short factoid answers. When extracting specific details such as customer number, always locate the 'Customer No.' label within the context and extract the number directly from that label's section. Focus on accuracy by verifying the label and its value in the same segment, and ensure the answer is concise, accurate, and based solely on the provided context.\", requires_opt=True)]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Loading Data: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:00<00:00, 192.43it/s]\n",
      "Predicting: step(8): 0.9083 across 2 samples, Max potential: 0.9083: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:01<00:00,  1.97it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-07-25 22:53:35 - [trainer.py:2230:_text_grad_constraint_propose_step] - Fail minibatch check, try next proposal: True, 0.9083333333333333 <= 0.9083333333333333\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Proposing:  40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 2/5 [00:06<00:10,  3.50s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Proposal: 3\n",
      "2025-07-25 22:53:38 - [trainer.py:2204:_text_grad_constraint_propose_step] - Propose time: 2.7773430347442627\n",
      "New prompts:  [PromptData(id='7c4cfe03-3711-427e-a485-2a8def6f6893', name='llm.task_desc_str', data=\"Answer questions with short factoid answers. Think step by step. Always locate the 'Customer No.' label in the context and extract the associated number directly from the same section. Do not rely on inference or assumptions. Ensure the answer is concise, accurate, and based solely on the provided context.\", requires_opt=True)]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Loading Data: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:00<00:00, 140.00it/s]\n",
      "Predicting: step(8): 0.9083 across 2 samples, Max potential: 0.9083: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:00<00:00,  2.11it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-07-25 22:53:39 - [trainer.py:2230:_text_grad_constraint_propose_step] - Fail minibatch check, try next proposal: True, 0.9083333333333333 <= 0.9083333333333333\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Proposing:  60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 3/5 [00:11<00:07,  3.81s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Proposal: 4\n",
      "2025-07-25 22:53:42 - [trainer.py:2204:_text_grad_constraint_propose_step] - Propose time: 2.2890608310699463\n",
      "New prompts:  [PromptData(id='7c4cfe03-3711-427e-a485-2a8def6f6893', name='llm.task_desc_str', data=\"Answer questions with short factoid answers. Always locate the 'Customer No.' label in the context, verify it, and extract the associated number directly from the same section. Do not include extraneous information. Focus on accuracy and consistency across diverse document layouts.\", requires_opt=True)]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Loading Data: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:00<00:00, 167.13it/s]\n",
      "Predicting: step(8): 0.9083 across 2 samples, Max potential: 0.9083: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:01<00:00,  1.29it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-07-25 22:53:44 - [trainer.py:2230:_text_grad_constraint_propose_step] - Fail minibatch check, try next proposal: True, 0.9083333333333333 <= 0.9083333333333333\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Proposing:  80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 4/5 [00:15<00:04,  4.01s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Proposal: 5\n",
      "2025-07-25 22:53:45 - [trainer.py:2204:_text_grad_constraint_propose_step] - Propose time: 1.459000825881958\n",
      "New prompts:  [PromptData(id='7c4cfe03-3711-427e-a485-2a8def6f6893', name='llm.task_desc_str', data='The invoice issuer is Heyl & Patterson', requires_opt=True)]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Loading Data: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:00<00:00, 282.77it/s]\n",
      "Predicting: step(8): 0.9083 across 2 samples, Max potential: 0.9083: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:00<00:00,  2.09it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-07-25 22:53:46 - [trainer.py:2230:_text_grad_constraint_propose_step] - Fail minibatch check, try next proposal: True, 0.9083333333333333 <= 0.9083333333333333\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Proposing: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5/5 [00:18<00:00,  3.65s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No proposal can improve the subset and full set, and val set\n",
      "Saving checkpoint to C:\\Users\\wuhan\\AppData\\Roaming\\adalflow\\ckpt\\HotPotQAAdal\\constrained_max_steps_12_21fb6_run_1.json\n",
      "Done with proposals\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Step: 8: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [08:53<00:00, 66.64s/it]\n",
      "Epoch:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 1/2 [08:53<08:53, 533.18s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Step: 9:   0%|          | 0/8 [00:00<?, ?it/s]\n",
      "Loading Data: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:00<00:00, 233.83it/s]\n",
      "Training: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:00<00:00,  5.18it/s]\n",
      "\n",
      "Loading Data: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:00<00:00, 210.08it/s]\n",
      "Calculating Loss: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:00<00:00, 31.59it/s]\n",
      "Evaluating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:00<00:00, 123.59it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Moving batch eval: EvaluationResult(avg_score=0.8633333333333333, per_item_scores=[0.5166666666666666, 0.8166666666666667, 0.95, 1.0, 1.0, 0.8166666666666667, 0.95, 1.0, 0.8166666666666667, 0.7666666666666667], additional_info=None)\n",
      "2025-07-25 22:53:48 - [trainer.py:2172:_text_grad_constraint_propose_step] - Moving batch acc: 0.8633333333333333\n",
      "Moving batch correct size: 10\n",
      "Moving batch error size: 0\n",
      "Subset Error size: 0\n",
      "Subset Correct size: 2\n",
      "Subset score: 0.9083333333333333\n",
      "2025-07-25 22:53:48 - [trainer.py:2178:_text_grad_constraint_propose_step] - Subset batch acc: 0.9083333333333333,0.9083333333333333\n",
      "Subset loss backward...\n",
      "Subset loss backward time: 2.782881021499634\n",
      "Optimizer propose...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Proposing:   0%|          | 0/5 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Proposal: 1\n",
      "2025-07-25 22:53:53 - [trainer.py:2204:_text_grad_constraint_propose_step] - Propose time: 2.2678420543670654\n",
      "New prompts:  [PromptData(id='7c4cfe03-3711-427e-a485-2a8def6f6893', name='llm.task_desc_str', data='Answer questions with short factoid answers. You will receive context (contain relevant facts). Think step by step. Focus on extracting the most relevant factoid directly answering the question. Do not include explanations or additional commentary. Ensure the answer is concise, accurate, and based solely on the provided context. Update more rapidly when steps are larger than 3.', requires_opt=True)]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Loading Data: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:00<00:00, 332.54it/s]\n",
      "Predicting: step(9): 0.9083 across 2 samples, Max potential: 0.9083: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:01<00:00,  1.93it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-07-25 22:53:55 - [trainer.py:2230:_text_grad_constraint_propose_step] - Fail minibatch check, try next proposal: True, 0.9083333333333333 <= 0.9083333333333333\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Proposing:  20%|â–ˆâ–ˆ        | 1/5 [00:03<00:14,  3.68s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Proposal: 2\n",
      "2025-07-25 22:53:56 - [trainer.py:2204:_text_grad_constraint_propose_step] - Propose time: 1.6745796203613281\n",
      "New prompts:  [PromptData(id='7c4cfe03-3711-427e-a485-2a8def6f6893', name='llm.task_desc_str', data='Answer questions with short factoid answers. You will receive context (contain relevant facts). Think step by step. Focus on extracting the most relevant factoid directly answering the question. Do not include explanations or additional commentary. Ensure the answer is concise, accurate, and based solely on the provided context. When the step count increases beyond 3, update your response more rapidly to reflect new information.', requires_opt=True)]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Loading Data: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:00<00:00, 266.53it/s]\n",
      "Predicting: step(9): 0.9083 across 2 samples, Max potential: 0.9083: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:01<00:00,  1.69it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-07-25 22:53:58 - [trainer.py:2230:_text_grad_constraint_propose_step] - Fail minibatch check, try next proposal: True, 0.9083333333333333 <= 0.9083333333333333\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Proposing:  40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 2/5 [00:07<00:10,  3.47s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Proposal: 3\n",
      "2025-07-25 22:54:00 - [trainer.py:2204:_text_grad_constraint_propose_step] - Propose time: 1.624986171722412\n",
      "New prompts:  [PromptData(id='7c4cfe03-3711-427e-a485-2a8def6f6893', name='llm.task_desc_str', data='Answer questions with short factoid answers. Think step by step. When steps are larger than 3, update the response more rapidly. Focus on extracting the most relevant fact directly answering the question based solely on the provided context. Do not include explanations or additional commentary.', requires_opt=True)]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Loading Data: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:00<00:00, 207.13it/s]\n",
      "Predicting: step(9): 0.9083 across 2 samples, Max potential: 0.9083: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:01<00:00,  1.50it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-07-25 22:54:01 - [trainer.py:2230:_text_grad_constraint_propose_step] - Fail minibatch check, try next proposal: True, 0.9083333333333333 <= 0.9083333333333333\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Proposing:  60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 3/5 [00:10<00:06,  3.49s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Proposal: 4\n",
      "2025-07-25 22:54:03 - [trainer.py:2204:_text_grad_constraint_propose_step] - Propose time: 1.8940811157226562\n",
      "New prompts:  [PromptData(id='7c4cfe03-3711-427e-a485-2a8def6f6893', name='llm.task_desc_str', data='Answer questions with short factoid answers. Focus solely on extracting the most relevant factual information from the context. Think step by step if needed. Do not include explanations or additional commentary. For large step numbers (greater than 3), update the answer more rapidly to reflect changes in the context.', requires_opt=True)]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Loading Data: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:00<00:00, 166.01it/s]\n",
      "Predicting: step(9): 0.95 across 2 samples, Max potential: 0.95: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:03<00:00,  1.50s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-07-25 22:54:07 - [trainer.py:2224:_text_grad_constraint_propose_step] - Pass minibatch check:True, 0.95 > 0.9083333333333333\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Loading Data: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 30/30 [00:00<00:00, 1299.97it/s]\n",
      "Predicting: step(9): 0.8712 across 26 samples, Max potential: 0.8883:  87%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 26/30 [00:07<00:01,  3.28it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimizer revert: 0.8709876543209876 <= 0.8883333333333333\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Proposing:  80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 4/5 [00:23<00:07,  7.38s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Proposal: 5\n",
      "2025-07-25 22:54:17 - [trainer.py:2204:_text_grad_constraint_propose_step] - Propose time: 2.1696770191192627\n",
      "New prompts:  [PromptData(id='7c4cfe03-3711-427e-a485-2a8def6f6893', name='llm.task_desc_str', data='Answer questions with short factoid answers. You will receive context (contain relevant facts). Think step by step. Focus on extracting the most relevant factoid directly answering the question. Do not include explanations or additional commentary. Ensure the answer is concise, accurate, and based solely on the provided context. When the step number exceeds 3, update the answer more rapidly to accommodate batch changes.', requires_opt=True)]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Loading Data: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:00<00:00, 202.74it/s]\n",
      "Predicting: step(9): 0.9083 across 2 samples, Max potential: 0.9083: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:01<00:00,  1.90it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-07-25 22:54:18 - [trainer.py:2230:_text_grad_constraint_propose_step] - Fail minibatch check, try next proposal: True, 0.9083333333333333 <= 0.9083333333333333\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Proposing: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5/5 [00:27<00:00,  5.51s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No proposal can improve the subset and full set, and val set\n",
      "Saving checkpoint to C:\\Users\\wuhan\\AppData\\Roaming\\adalflow\\ckpt\\HotPotQAAdal\\constrained_max_steps_12_21fb6_run_1.json\n",
      "Done with proposals\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Step: 10:  12%|â–ˆâ–Ž        | 1/8 [00:31<03:43, 31.96s/it]\n",
      "Loading Data: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:00<00:00, 127.08it/s]\n",
      "Training: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:00<00:00,  5.17it/s]\n",
      "\n",
      "Loading Data: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:00<00:00, 567.87it/s]\n",
      "Calculating Loss: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:00<00:00, 87.16it/s]\n",
      "Evaluating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 14/14 [00:00<00:00, 184.13it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Moving batch eval: EvaluationResult(avg_score=0.8857142857142856, per_item_scores=[0.5166666666666666, 0.8166666666666667, 0.95, 1.0, 1.0, 0.8166666666666667, 0.95, 1.0, 0.8166666666666667, 0.7666666666666667, 1.0, 0.8166666666666667, 0.95, 1.0], additional_info=None)\n",
      "2025-07-25 22:54:20 - [trainer.py:2172:_text_grad_constraint_propose_step] - Moving batch acc: 0.8857142857142856\n",
      "Moving batch correct size: 14\n",
      "Moving batch error size: 0\n",
      "Subset Error size: 0\n",
      "Subset Correct size: 2\n",
      "Subset score: 0.8833333333333333\n",
      "2025-07-25 22:54:20 - [trainer.py:2178:_text_grad_constraint_propose_step] - Subset batch acc: 0.8833333333333333,0.8833333333333333\n",
      "Subset loss backward...\n",
      "Subset loss backward time: 3.433289051055908\n",
      "Optimizer propose...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Proposing:   0%|          | 0/5 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Proposal: 1\n",
      "2025-07-25 22:54:27 - [trainer.py:2204:_text_grad_constraint_propose_step] - Propose time: 3.603412628173828\n",
      "New prompts:  [PromptData(id='7c4cfe03-3711-427e-a485-2a8def6f6893', name='llm.task_desc_str', data='Answer questions with short factoid answers. You will receive context (contain relevant facts). Think step by step. Focus on extracting the most relevant factoid directly answering the question. Do not include explanations or additional commentary. Ensure the answer is concise, accurate, and based solely on the provided context. When stating names of organizations or entities, include their full official designation as it appears in the context.', requires_opt=True)]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Loading Data: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:00<00:00, 117.47it/s]\n",
      "Predicting: step(10): 0.8833 across 2 samples, Max potential: 0.8833: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:02<00:00,  1.33s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-07-25 22:54:30 - [trainer.py:2230:_text_grad_constraint_propose_step] - Fail minibatch check, try next proposal: True, 0.8833333333333333 <= 0.8833333333333333\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Proposing:  20%|â–ˆâ–ˆ        | 1/5 [00:06<00:26,  6.74s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Proposal: 2\n",
      "2025-07-25 22:54:37 - [trainer.py:2204:_text_grad_constraint_propose_step] - Propose time: 6.978186130523682\n",
      "New prompts:  [PromptData(id='7c4cfe03-3711-427e-a485-2a8def6f6893', name='llm.task_desc_str', data='Task description for the language model, used with the following template: {{task_desc_str}} {{output_format_str}} <START_OF_USER> Context: {{context}} Question: {{question}} <END_OF_USER>\\nAnswer: Provide a concise, fact-based response that includes the full official name and designation exactly as given in the context, including any divisions or corporate designations. Focus on extracting the most relevant and precise official designation. Do not include explanations or additional commentary.', requires_opt=True)]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Loading Data: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:00<00:00, 189.76it/s]\n",
      "Predicting: step(10): 0.975 across 2 samples, Max potential: 0.975: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:39<00:00, 19.71s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-07-25 22:55:17 - [trainer.py:2224:_text_grad_constraint_propose_step] - Pass minibatch check:True, 0.975 > 0.8833333333333333\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Loading Data: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 30/30 [00:00<00:00, 1204.79it/s]\n",
      "Predicting: step(10): 0.8452 across 21 samples, Max potential: 0.8917:  70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 21/30 [00:08<00:03,  2.38it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimizer revert: 0.8439393939393939 <= 0.8883333333333333\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Proposing:  40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 2/5 [01:02<01:46, 35.60s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Proposal: 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Error at parsing JSON string: Got invalid JSON object with yaml.safe_load. Error: while parsing a flow mapping\n",
      "  in \"<unicode string>\", line 1, column 1:\n",
      "    {\n",
      "    ^\n",
      "expected ',' or '}', but got '<scalar>'\n",
      "  in \"<unicode string>\", line 4, column 29:\n",
      "        \"proposed_variable\": \"{\"reasoning\": \"The context explici ... \n",
      "                                ^. Got JSON string: {\n",
      "    \"reasoning\": \"The context consistently mentions the full official name 'Leo Burnett USA, a division of Leo Burnett Company, Inc.' as the creator of the document. The previous model outputs only 'Leo Burnett USA', which omits the essential official designation. To match the ground truth and improve accuracy, the prompt should explicitly instruct the model to include the entire official name and designation exactly as provided in the context.\",\n",
      "    \"method\": \"Rephrase existing instruction (prompting) + add explicit guidance to include full official names and designations\",\n",
      "    \"proposed_variable\": \"{\"reasoning\": \"The context explicitly states the full official name and designation of the company as 'Leo Burnett USA, a division of Leo Burnett Company, Inc.' To ensure the model outputs the complete and correct official name, the instruction must explicitly require including the full official designation in the answer. This will help the model produce precise and aligned responses across the batch.\",\"method\": \"Rephrase existing instruction (prompting) + add explicit guidance to include full official names and designations\",\"proposed_variable\": \"Answer with the full official name and designation exactly as it appears in the context, including 'a division of Leo Burnett Company, Inc.'.\"}\"\n",
      "}\n",
      "Error at parsing output: Error: Got invalid JSON object with yaml.safe_load. Error: while parsing a flow mapping\n",
      "  in \"<unicode string>\", line 1, column 1:\n",
      "    {\n",
      "    ^\n",
      "expected ',' or '}', but got '<scalar>'\n",
      "  in \"<unicode string>\", line 4, column 29:\n",
      "        \"proposed_variable\": \"{\"reasoning\": \"The context explici ... \n",
      "                                ^. Got JSON string: {\n",
      "    \"reasoning\": \"The context consistently mentions the full official name 'Leo Burnett USA, a division of Leo Burnett Company, Inc.' as the creator of the document. The previous model outputs only 'Leo Burnett USA', which omits the essential official designation. To match the ground truth and improve accuracy, the prompt should explicitly instruct the model to include the entire official name and designation exactly as provided in the context.\",\n",
      "    \"method\": \"Rephrase existing instruction (prompting) + add explicit guidance to include full official names and designations\",\n",
      "    \"proposed_variable\": \"{\"reasoning\": \"The context explicitly states the full official name and designation of the company as 'Leo Burnett USA, a division of Leo Burnett Company, Inc.' To ensure the model outputs the complete and correct official name, the instruction must explicitly require including the full official designation in the answer. This will help the model produce precise and aligned responses across the batch.\",\"method\": \"Rephrase existing instruction (prompting) + add explicit guidance to include full official names and designations\",\"proposed_variable\": \"Answer with the full official name and designation exactly as it appears in the context, including 'a division of Leo Burnett Company, Inc.'.\"}\"\n",
      "}\n",
      "Error processing the output processors: Error: Error: Got invalid JSON object with yaml.safe_load. Error: while parsing a flow mapping\n",
      "  in \"<unicode string>\", line 1, column 1:\n",
      "    {\n",
      "    ^\n",
      "expected ',' or '}', but got '<scalar>'\n",
      "  in \"<unicode string>\", line 4, column 29:\n",
      "        \"proposed_variable\": \"{\"reasoning\": \"The context explici ... \n",
      "                                ^. Got JSON string: {\n",
      "    \"reasoning\": \"The context consistently mentions the full official name 'Leo Burnett USA, a division of Leo Burnett Company, Inc.' as the creator of the document. The previous model outputs only 'Leo Burnett USA', which omits the essential official designation. To match the ground truth and improve accuracy, the prompt should explicitly instruct the model to include the entire official name and designation exactly as provided in the context.\",\n",
      "    \"method\": \"Rephrase existing instruction (prompting) + add explicit guidance to include full official names and designations\",\n",
      "    \"proposed_variable\": \"{\"reasoning\": \"The context explicitly states the full official name and designation of the company as 'Leo Burnett USA, a division of Leo Burnett Company, Inc.' To ensure the model outputs the complete and correct official name, the instruction must explicitly require including the full official designation in the answer. This will help the model produce precise and aligned responses across the batch.\",\"method\": \"Rephrase existing instruction (prompting) + add explicit guidance to include full official names and designations\",\"proposed_variable\": \"Answer with the full official name and designation exactly as it appears in the context, including 'a division of Leo Burnett Company, Inc.'.\"}\"\n",
      "}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-07-25 22:55:28 - [trainer.py:2204:_text_grad_constraint_propose_step] - Propose time: 2.1000757217407227\n",
      "New prompts:  [PromptData(id='7c4cfe03-3711-427e-a485-2a8def6f6893', name='llm.task_desc_str', data='{\\n    \"reasoning\": \"The context consistently mentions the full official name \\'Leo Burnett USA, a division of Leo Burnett Company, Inc.\\' as the creator of the document. The previous model outputs only \\'Leo Burnett USA\\', which omits the essential official designation. To match the ground truth and improve accuracy, the prompt should explicitly instruct the model to include the entire official name and designation exactly as provided in the context.\",\\n    \"method\": \"Rephrase existing instruction (prompting) + add explicit guidance to include full official names and designations\",\\n    \"proposed_variable\": \"{\"reasoning\": \"The context explicitly states the full official name and designation of the company as \\'Leo Burnett USA, a division of Leo Burnett Company, Inc.\\' To ensure the model outputs the complete and correct official name, the instruction must explicitly require including the full official designation in the answer. This will help the model produce precise and aligned responses across the batch.\",\"method\": \"Rephrase existing instruction (prompting) + add explicit guidance to include full official names and designations\",\"proposed_variable\": \"Answer with the full official name and designation exactly as it appears in the context, including \\'a division of Leo Burnett Company, Inc.\\'.\"}\"\\n}', requires_opt=True)]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Loading Data: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:00<00:00, 110.33it/s]\n",
      "Predicting: step(10): 0.975 across 2 samples, Max potential: 0.975: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:03<00:00,  1.53s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-07-25 22:55:32 - [trainer.py:2224:_text_grad_constraint_propose_step] - Pass minibatch check:True, 0.975 > 0.8833333333333333\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Loading Data: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 30/30 [00:00<00:00, 1142.03it/s]\n",
      "Predicting: step(10): 0.8204 across 18 samples, Max potential: 0.8922:  60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 18/30 [00:12<00:08,  1.48it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimizer revert: 0.8149122807017544 <= 0.8883333333333333\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Proposing:  60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 3/5 [01:20<00:55, 27.60s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Proposal: 4\n",
      "2025-07-25 22:55:46 - [trainer.py:2204:_text_grad_constraint_propose_step] - Propose time: 2.3317854404449463\n",
      "New prompts:  [PromptData(id='7c4cfe03-3711-427e-a485-2a8def6f6893', name='llm.task_desc_str', data='Task description for the language model, used with the following template: {{task_desc_str}} {{output_format_str}} <START_OF_USER> Context: {{context}} Question: {{question}} <END_OF_USER> Please answer with the full official name and designation of the creating company exactly as it appears in the context, including any divisions or legal designations.', requires_opt=True)]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Loading Data: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:00<00:00, 188.23it/s]\n",
      "Predicting: step(10): 0.975 across 2 samples, Max potential: 0.975: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:00<00:00,  2.12it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-07-25 22:55:48 - [trainer.py:2224:_text_grad_constraint_propose_step] - Pass minibatch check:True, 0.975 > 0.8833333333333333\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Loading Data: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 30/30 [00:00<00:00, 804.62it/s]\n",
      "Predicting: step(10): 0.6667 across 10 samples, Max potential: 0.8889:  33%|â–ˆâ–ˆâ–ˆâ–Ž      | 10/30 [00:09<00:19,  1.02it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimizer revert: 0.6787878787878788 <= 0.8883333333333333\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Proposing:  80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 4/5 [01:34<00:22, 22.09s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Proposal: 5\n",
      "2025-07-25 22:56:00 - [trainer.py:2204:_text_grad_constraint_propose_step] - Propose time: 1.8859953880310059\n",
      "New prompts:  [PromptData(id='7c4cfe03-3711-427e-a485-2a8def6f6893', name='llm.task_desc_str', data=\"Answer questions with short factoid answers. You will receive context (contain relevant facts). Think step by step. Focus on extracting the most relevant factoid directly answering the question. Include the full official name and designation as it appears in the context, such as 'a division of Leo Burnett Company, Inc.' Ensure the answer is concise, accurate, and based solely on the provided context.\", requires_opt=True)]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Loading Data: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:00<00:00, 302.21it/s]\n",
      "Predicting: step(10): 0.975 across 2 samples, Max potential: 0.975: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:00<00:00,  2.36it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-07-25 22:56:01 - [trainer.py:2224:_text_grad_constraint_propose_step] - Pass minibatch check:True, 0.975 > 0.8833333333333333\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Loading Data: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 30/30 [00:00<00:00, 1774.19it/s]\n",
      "Predicting: step(10): 0.8712 across 26 samples, Max potential: 0.8883:  87%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 26/30 [00:09<00:01,  2.75it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimizer revert: 0.8709876543209876 <= 0.8883333333333333\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Proposing: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5/5 [01:46<00:00, 21.39s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No proposal can improve the subset and full set, and val set\n",
      "Saving checkpoint to C:\\Users\\wuhan\\AppData\\Roaming\\adalflow\\ckpt\\HotPotQAAdal\\constrained_max_steps_12_21fb6_run_1.json\n",
      "Done with proposals\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Step: 11:  25%|â–ˆâ–ˆâ–Œ       | 2/8 [02:23<07:53, 78.95s/it]\n",
      "Loading Data: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:00<00:00, 165.85it/s]\n",
      "Training: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:01<00:00,  2.24it/s]\n",
      "\n",
      "Loading Data: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:00<00:00, 232.37it/s]\n",
      "Calculating Loss: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:00<00:00, 33.20it/s]\n",
      "Evaluating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 18/18 [00:00<00:00, 139.42it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Moving batch eval: EvaluationResult(avg_score=0.8851851851851852, per_item_scores=[0.5166666666666666, 0.8166666666666667, 0.95, 1.0, 1.0, 0.8166666666666667, 0.95, 1.0, 0.8166666666666667, 0.7666666666666667, 1.0, 0.8166666666666667, 0.95, 1.0, 1.0, 0.8166666666666667, 0.95, 0.7666666666666667], additional_info=None)\n",
      "2025-07-25 22:56:13 - [trainer.py:2172:_text_grad_constraint_propose_step] - Moving batch acc: 0.8851851851851852\n",
      "Moving batch correct size: 18\n",
      "Moving batch error size: 0\n",
      "Subset Error size: 0\n",
      "Subset Correct size: 2\n",
      "Subset score: 0.7916666666666667\n",
      "2025-07-25 22:56:13 - [trainer.py:2178:_text_grad_constraint_propose_step] - Subset batch acc: 0.7916666666666667,0.7916666666666667\n",
      "Subset loss backward...\n",
      "Subset loss backward time: 6.133310556411743\n",
      "Optimizer propose...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Proposing:   0%|          | 0/5 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Proposal: 1\n",
      "2025-07-25 22:56:21 - [trainer.py:2204:_text_grad_constraint_propose_step] - Propose time: 1.929619550704956\n",
      "New prompts:  [PromptData(id='7c4cfe03-3711-427e-a485-2a8def6f6893', name='llm.task_desc_str', data='Copiadora Gouldsvey, 12 Calle Guisqueya, HATO Rey PR 00917-1236', requires_opt=True)]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Loading Data: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:00<00:00, 141.20it/s]\n",
      "Predicting: step(11): 0.7917 across 2 samples, Max potential: 0.7917: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:01<00:00,  1.94it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-07-25 22:56:22 - [trainer.py:2230:_text_grad_constraint_propose_step] - Fail minibatch check, try next proposal: True, 0.7916666666666667 <= 0.7916666666666667\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Proposing:  20%|â–ˆâ–ˆ        | 1/5 [00:03<00:13,  3.40s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Proposal: 2\n",
      "2025-07-25 22:56:24 - [trainer.py:2204:_text_grad_constraint_propose_step] - Propose time: 1.8057801723480225\n",
      "New prompts:  [PromptData(id='7c4cfe03-3711-427e-a485-2a8def6f6893', name='llm.task_desc_str', data='Copiadora Gouldsvey, 12 Calle Guisqueya, HATO Rey PR 00917-1236', requires_opt=True)]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Loading Data: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:00<00:00, 229.15it/s]\n",
      "Predicting: step(11): 0.7917 across 2 samples, Max potential: 0.7917: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:00<00:00, 21.08it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-07-25 22:56:25 - [trainer.py:2230:_text_grad_constraint_propose_step] - Fail minibatch check, try next proposal: True, 0.7916666666666667 <= 0.7916666666666667\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Proposing:  40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 2/5 [00:05<00:08,  2.76s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Proposal: 3\n",
      "2025-07-25 22:56:27 - [trainer.py:2204:_text_grad_constraint_propose_step] - Propose time: 1.861696720123291\n",
      "New prompts:  [PromptData(id='7c4cfe03-3711-427e-a485-2a8def6f6893', name='llm.task_desc_str', data='Copiadora Gouldsvey, 12 Calle Guisqueya, HATO Rey PR 00917-1236', requires_opt=True)]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Loading Data: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:00<00:00, 474.07it/s]\n",
      "Predicting: step(11): 0.7917 across 2 samples, Max potential: 0.7917: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:00<00:00, 98.77it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-07-25 22:56:27 - [trainer.py:2230:_text_grad_constraint_propose_step] - Fail minibatch check, try next proposal: True, 0.7916666666666667 <= 0.7916666666666667\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Proposing:  60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 3/5 [00:07<00:04,  2.48s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Proposal: 4\n",
      "2025-07-25 22:56:28 - [trainer.py:2204:_text_grad_constraint_propose_step] - Propose time: 1.3744637966156006\n",
      "New prompts:  [PromptData(id='7c4cfe03-3711-427e-a485-2a8def6f6893', name='llm.task_desc_str', data='Copiadora Gouldsvey, 12 Calle Guisqueya, HATO Rey PR 00917-1236', requires_opt=True)]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Loading Data: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:00<00:00, 395.73it/s]\n",
      "Predicting: step(11): 0.7917 across 2 samples, Max potential: 0.7917: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:00<00:00, 131.83it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-07-25 22:56:29 - [trainer.py:2230:_text_grad_constraint_propose_step] - Fail minibatch check, try next proposal: True, 0.7916666666666667 <= 0.7916666666666667\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Proposing:  80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 4/5 [00:09<00:02,  2.19s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Proposal: 5\n",
      "2025-07-25 22:56:30 - [trainer.py:2204:_text_grad_constraint_propose_step] - Propose time: 1.3258843421936035\n",
      "New prompts:  [PromptData(id='7c4cfe03-3711-427e-a485-2a8def6f6893', name='llm.task_desc_str', data='Copiadora Gouldsvey, 12 Calle Guisqueya, HATO Rey PR 00917-1236', requires_opt=True)]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Loading Data: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:00<00:00, 229.23it/s]\n",
      "Predicting: step(11): 0.7917 across 2 samples, Max potential: 0.7917: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:00<00:00, 100.51it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-07-25 22:56:30 - [trainer.py:2230:_text_grad_constraint_propose_step] - Fail minibatch check, try next proposal: True, 0.7916666666666667 <= 0.7916666666666667\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Proposing: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5/5 [00:11<00:00,  2.27s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No proposal can improve the subset and full set, and val set\n",
      "Saving checkpoint to C:\\Users\\wuhan\\AppData\\Roaming\\adalflow\\ckpt\\HotPotQAAdal\\constrained_max_steps_12_21fb6_run_1.json\n",
      "Done with proposals\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Step: 12:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [02:43<04:20, 52.08s/it]\n",
      "Loading Data: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:00<00:00, 213.10it/s]\n",
      "Training: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:00<00:00,  5.40it/s]\n",
      "\n",
      "Loading Data: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:00<00:00, 299.04it/s]\n",
      "Calculating Loss: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:00<00:00, 50.00it/s]\n",
      "Evaluating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 22/22 [00:00<00:00, 124.24it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Moving batch eval: EvaluationResult(avg_score=0.8787878787878788, per_item_scores=[0.5166666666666666, 0.8166666666666667, 0.95, 1.0, 1.0, 0.8166666666666667, 0.95, 1.0, 0.8166666666666667, 0.7666666666666667, 1.0, 0.8166666666666667, 0.95, 1.0, 1.0, 0.8166666666666667, 0.95, 0.7666666666666667, 0.8666666666666667, 1.0, 0.7166666666666667, 0.8166666666666667], additional_info=None)\n",
      "2025-07-25 22:56:32 - [trainer.py:2172:_text_grad_constraint_propose_step] - Moving batch acc: 0.8783333333333332\n",
      "Moving batch correct size: 20\n",
      "Moving batch error size: 0\n",
      "Subset Error size: 0\n",
      "Subset Correct size: 2\n",
      "Subset score: 0.975\n",
      "2025-07-25 22:56:32 - [trainer.py:2178:_text_grad_constraint_propose_step] - Subset batch acc: 0.975,0.975\n",
      "Subset loss backward...\n",
      "Subset loss backward time: 1.578230857849121\n",
      "Optimizer propose...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Proposing:   0%|          | 0/5 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Proposal: 1\n",
      "2025-07-25 22:56:36 - [trainer.py:2204:_text_grad_constraint_propose_step] - Propose time: 1.9395856857299805\n",
      "New prompts:  [PromptData(id='7c4cfe03-3711-427e-a485-2a8def6f6893', name='llm.task_desc_str', data='The check number of the payment is 0130520468.', requires_opt=True)]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Loading Data: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:00<00:00, 203.69it/s]\n",
      "Predicting: step(12): 0.975 across 2 samples, Max potential: 0.975: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:01<00:00,  1.15it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-07-25 22:56:38 - [trainer.py:2230:_text_grad_constraint_propose_step] - Fail minibatch check, try next proposal: True, 0.975 <= 0.975\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Proposing:  20%|â–ˆâ–ˆ        | 1/5 [00:04<00:16,  4.12s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Proposal: 2\n",
      "2025-07-25 22:56:39 - [trainer.py:2204:_text_grad_constraint_propose_step] - Propose time: 1.3173415660858154\n",
      "New prompts:  [PromptData(id='7c4cfe03-3711-427e-a485-2a8def6f6893', name='llm.task_desc_str', data='Question: What is the check number of the payment?\\nAnswer: The check number is 0130520468.', requires_opt=True)]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Loading Data: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:00<00:00, 161.67it/s]\n",
      "Predicting: step(12): 0.975 across 2 samples, Max potential: 0.975: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:01<00:00,  1.88it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-07-25 22:56:40 - [trainer.py:2230:_text_grad_constraint_propose_step] - Fail minibatch check, try next proposal: True, 0.975 <= 0.975\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Proposing:  40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 2/5 [00:07<00:10,  3.39s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Proposal: 3\n",
      "2025-07-25 22:56:43 - [trainer.py:2204:_text_grad_constraint_propose_step] - Propose time: 2.136554002761841\n",
      "New prompts:  [PromptData(id='7c4cfe03-3711-427e-a485-2a8def6f6893', name='llm.task_desc_str', data='Answer questions with short factoid answers. You will receive context (contain relevant facts). Think step by step. Focus on extracting the specific detail asked in the question directly from the explicit key details section of the context. Do not include explanations or additional commentary. Ensure the answer is concise, accurate, and based solely on the provided context.', requires_opt=True)]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Loading Data: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:00<00:00, 403.47it/s]\n",
      "Predicting: step(12): 0.975 across 2 samples, Max potential: 0.975: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:00<00:00,  3.28it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-07-25 22:56:43 - [trainer.py:2230:_text_grad_constraint_propose_step] - Fail minibatch check, try next proposal: True, 0.975 <= 0.975\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Proposing:  60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 3/5 [00:10<00:06,  3.23s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Proposal: 4\n",
      "2025-07-25 22:56:46 - [trainer.py:2204:_text_grad_constraint_propose_step] - Propose time: 2.5393359661102295\n",
      "New prompts:  [PromptData(id='7c4cfe03-3711-427e-a485-2a8def6f6893', name='llm.task_desc_str', data='Answer questions with short factoid answers. You will receive context (contain relevant facts). Identify and extract the specific key detail (e.g., issuer, check number, company name, address) directly from the context, citing the exact text when possible. Do not include explanations or additional commentary. Focus on concise, accurate extraction based solely on the provided context.', requires_opt=True)]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Loading Data: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:00<00:00, 494.55it/s]\n",
      "Predicting: step(12): 0.975 across 2 samples, Max potential: 0.975: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:00<00:00,  2.50it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-07-25 22:56:47 - [trainer.py:2230:_text_grad_constraint_propose_step] - Fail minibatch check, try next proposal: True, 0.975 <= 0.975\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Proposing:  80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 4/5 [00:13<00:03,  3.40s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Proposal: 5\n",
      "2025-07-25 22:56:48 - [trainer.py:2204:_text_grad_constraint_propose_step] - Propose time: 1.1289136409759521\n",
      "New prompts:  [PromptData(id='7c4cfe03-3711-427e-a485-2a8def6f6893', name='llm.task_desc_str', data=\"Output the check number exactly as it appears in the context, using a clear and concise format: 'The check number is 0130520468.'\", requires_opt=True)]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Loading Data: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:00<00:00, 456.35it/s]\n",
      "Predicting: step(12): 0.6667 across 2 samples, Max potential: 0.6667: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:04<00:00,  2.01s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-07-25 22:56:53 - [trainer.py:2230:_text_grad_constraint_propose_step] - Fail minibatch check, try next proposal: True, 0.6666666666666667 <= 0.975\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Proposing: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5/5 [00:19<00:00,  3.84s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No proposal can improve the subset and full set, and val set\n",
      "Saving checkpoint to C:\\Users\\wuhan\\AppData\\Roaming\\adalflow\\ckpt\\HotPotQAAdal\\constrained_max_steps_12_21fb6_run_1.json\n",
      "Done with proposals\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Step: 12:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 4/8 [03:06<02:41, 40.33s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reached max steps\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Step: 12:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 4/8 [03:06<03:06, 46.56s/it]\n",
      "Epoch: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [11:59<00:00, 359.73s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting step: 12\n",
      "steps [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12]\n",
      "Training time: 720.5202217102051s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading Data: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 30/30 [00:00<00:00, 2440.54it/s]\n",
      "Predicting: step(0): 0.87 across 30 samples, Max potential: 0.87: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 30/30 [00:08<00:00,  3.38it/s]    \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ckpt_file: C:\\Users\\wuhan\\AppData\\Roaming\\adalflow\\ckpt\\HotPotQAAdal\\constrained_max_steps_12_21fb6_run_1.json\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'C:\\\\Users\\\\wuhan\\\\AppData\\\\Roaming\\\\adalflow\\\\ckpt\\\\HotPotQAAdal\\\\constrained_max_steps_12_21fb6_run_1.json'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train(\n",
    "    task_model_cliet=gpt4_model[\"model_client\"],\n",
    "    task_model_kwargs=gpt4_model[\"model_kwargs\"],\n",
    "    optimizer_model_config=gpt4_model,\n",
    "    backward_engine_model_config=gpt4_model,\n",
    "    max_steps=12,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7c6442a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_training_single(file):\n",
    "    with open(file) as f:\n",
    "        data = json.load(f)\n",
    "\n",
    "    val_scores = data[\"val_scores\"]\n",
    "    start_test_score = data[\"test_scores\"][0]\n",
    "    end_test_score = data[\"test_score\"]\n",
    "\n",
    "    plt.figure(figsize=(12, 6))\n",
    "\n",
    "    # Plot validation scores as a continuous line\n",
    "    plt.plot(\n",
    "        val_scores,\n",
    "        label=\"Validation Scores\",\n",
    "        marker=\"o\",\n",
    "        markersize=5,\n",
    "        linewidth=1.5,\n",
    "        color=\"tab:blue\",\n",
    "    )\n",
    "\n",
    "    # Plot test scores as individual markers\n",
    "    plt.scatter(\n",
    "        0,\n",
    "        start_test_score,\n",
    "        s=100,\n",
    "        marker=\"D\",\n",
    "        color=\"tab:orange\",\n",
    "        edgecolor=\"black\",\n",
    "        label=\"Initial Test Score\",\n",
    "    )\n",
    "    plt.scatter(\n",
    "        len(val_scores) - 1,\n",
    "        end_test_score,\n",
    "        s=100,\n",
    "        marker=\"D\",\n",
    "        color=\"tab:green\",\n",
    "        edgecolor=\"black\",\n",
    "        label=\"Final Test Score\",\n",
    "    )\n",
    "\n",
    "    plt.title(\"AdalFlow Promp Optimization Training Progress\", fontsize=14, pad=20)\n",
    "    plt.xlabel(\"Training Steps\", fontsize=12)\n",
    "    plt.ylabel(\"GEval Score\", fontsize=12)\n",
    "    plt.legend(loc=\"lower right\", frameon=True)\n",
    "    plt.grid(True, linestyle=\"--\", alpha=0.6)\n",
    "\n",
    "    # Set x-axis to show only integer steps\n",
    "    plt.xticks(range(0, len(val_scores) + 1, max(1, len(val_scores) // 10)))\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1732102f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1200x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "file = 'C:\\\\Users\\\\wuhan\\\\AppData\\\\Roaming\\\\adalflow\\\\ckpt\\\\HotPotQAAdal\\\\constrained_max_steps_12_21fb6_run_1.json'\n",
    "plot_training_single(file)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b35d38b",
   "metadata": {},
   "source": [
    "### Understand the JSON Output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "948f3905",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['steps', 'val_scores', 'test_scores', 'step_results', 'effective_measure', 'validate_stats', 'time_stamp', 'total_time', 'test_score', 'trainer_state'])\n"
     ]
    }
   ],
   "source": [
    "with open(file) as f:\n",
    "    data = json.load(f)\n",
    "print(data.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0fe56f33",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8699999999999999\n",
      "6\n",
      "Initial Prompt: Answer questions with short factoid answers.\n",
      "                    You will receive context(contain relevant facts).\n",
      "                    Think step by step.\n",
      "                \n",
      "Best Prompt: Answer questions with short factoid answers. You will receive context (contain relevant facts). Think step by step. Focus on extracting the most relevant factoid directly answering the question. Do not include explanations or additional commentary. Ensure the answer is concise, accurate, and based solely on the provided context.\n"
     ]
    }
   ],
   "source": [
    "print(data['test_score'])\n",
    "\n",
    "best_idx = data['val_scores'].index(max(data['val_scores']))\n",
    "print(best_idx)\n",
    "\n",
    "best_prompt = data['step_results'][best_idx]['prompt'][0]['data']\n",
    "initial_prompt = data['step_results'][0]['prompt'][0]['data']\n",
    "print('Initial Prompt:', initial_prompt)\n",
    "print('Best Prompt:', best_prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "409b1e3e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step: 0\n",
      "val_score: 0.8849999999999999\n",
      "test_score: 0.8661111111111112\n",
      "attempted_val_score: None\n",
      "1 prompt: Answer questions with short factoid answers.\n",
      "                    You will receive context(contain relevant facts).\n",
      "                    Think step by step.\n",
      "                \n",
      "\n",
      "step: 1\n",
      "val_score: 0.8849999999999999\n",
      "test_score: 0.8661111111111112\n",
      "attempted_val_score: 0.8833333333333333\n",
      "1 prompt: Answer questions with short factoid answers.\n",
      "                    You will receive context(contain relevant facts).\n",
      "                    Think step by step.\n",
      "                \n",
      "\n",
      "step: 2\n",
      "val_score: 0.8849999999999999\n",
      "test_score: 0.8661111111111112\n",
      "attempted_val_score: 0.638888888888889\n",
      "1 prompt: Answer questions with short factoid answers.\n",
      "                    You will receive context(contain relevant facts).\n",
      "                    Think step by step.\n",
      "                \n",
      "\n",
      "step: 3\n",
      "val_score: 0.8849999999999999\n",
      "test_score: 0.8661111111111112\n",
      "attempted_val_score: 0.7388888888888889\n",
      "1 prompt: Answer questions with short factoid answers.\n",
      "                    You will receive context(contain relevant facts).\n",
      "                    Think step by step.\n",
      "                \n",
      "\n",
      "step: 4\n",
      "val_score: 0.8849999999999999\n",
      "test_score: 0.8661111111111112\n",
      "attempted_val_score: 0.8052631578947368\n",
      "1 prompt: Answer questions with short factoid answers.\n",
      "                    You will receive context(contain relevant facts).\n",
      "                    Think step by step.\n",
      "                \n",
      "\n",
      "step: 5\n",
      "val_score: 0.8849999999999999\n",
      "test_score: 0.8661111111111112\n",
      "attempted_val_score: 0.8697530864197531\n",
      "1 prompt: Answer questions with short factoid answers.\n",
      "                    You will receive context(contain relevant facts).\n",
      "                    Think step by step.\n",
      "                \n",
      "\n",
      "step: 6\n",
      "val_score: 0.8883333333333333\n",
      "test_score: None\n",
      "attempted_val_score: None\n",
      "1 prompt: Answer questions with short factoid answers. You will receive context (contain relevant facts). Think step by step. Focus on extracting the most relevant factoid directly answering the question. Do not include explanations or additional commentary. Ensure the answer is concise, accurate, and based solely on the provided context.\n",
      "\n",
      "step: 7\n",
      "val_score: 0.8883333333333333\n",
      "test_score: None\n",
      "attempted_val_score: 0.6666666666666666\n",
      "1 prompt: Answer questions with short factoid answers. You will receive context (contain relevant facts). Think step by step. Focus on extracting the most relevant factoid directly answering the question. Do not include explanations or additional commentary. Ensure the answer is concise, accurate, and based solely on the provided context.\n",
      "\n",
      "step: 8\n",
      "val_score: 0.8883333333333333\n",
      "test_score: None\n",
      "attempted_val_score: 0.9083333333333333\n",
      "1 prompt: Answer questions with short factoid answers. You will receive context (contain relevant facts). Think step by step. Focus on extracting the most relevant factoid directly answering the question. Do not include explanations or additional commentary. Ensure the answer is concise, accurate, and based solely on the provided context.\n",
      "\n",
      "step: 9\n",
      "val_score: 0.8883333333333333\n",
      "test_score: None\n",
      "attempted_val_score: 0.9083333333333333\n",
      "1 prompt: Answer questions with short factoid answers. You will receive context (contain relevant facts). Think step by step. Focus on extracting the most relevant factoid directly answering the question. Do not include explanations or additional commentary. Ensure the answer is concise, accurate, and based solely on the provided context.\n",
      "\n",
      "step: 10\n",
      "val_score: 0.8883333333333333\n",
      "test_score: None\n",
      "attempted_val_score: 0.8709876543209876\n",
      "1 prompt: Answer questions with short factoid answers. You will receive context (contain relevant facts). Think step by step. Focus on extracting the most relevant factoid directly answering the question. Do not include explanations or additional commentary. Ensure the answer is concise, accurate, and based solely on the provided context.\n",
      "\n",
      "step: 11\n",
      "val_score: 0.8883333333333333\n",
      "test_score: None\n",
      "attempted_val_score: 0.7916666666666667\n",
      "1 prompt: Answer questions with short factoid answers. You will receive context (contain relevant facts). Think step by step. Focus on extracting the most relevant factoid directly answering the question. Do not include explanations or additional commentary. Ensure the answer is concise, accurate, and based solely on the provided context.\n",
      "\n",
      "step: 12\n",
      "val_score: 0.8883333333333333\n",
      "test_score: None\n",
      "attempted_val_score: 0.6666666666666667\n",
      "1 prompt: Answer questions with short factoid answers. You will receive context (contain relevant facts). Think step by step. Focus on extracting the most relevant factoid directly answering the question. Do not include explanations or additional commentary. Ensure the answer is concise, accurate, and based solely on the provided context.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for step in data['step_results']:\n",
    "    for k, v in step.items():\n",
    "        if k == 'prompt':\n",
    "            print(len(v), f\"prompt: {v[0]['data']}\")\n",
    "        else:\n",
    "            print(f\"{k}: {v}\")\n",
    "    print()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
