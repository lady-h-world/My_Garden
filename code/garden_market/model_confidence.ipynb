{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Licensed under the MIT License.\n",
    "\n",
    "Copyright (c) 2021-2031. All rights reserved.\n",
    "\n",
    "# Confidence Interval of Model Performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from supervised.automl import AutoML\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import r2_score, balanced_accuracy_score\n",
    "from sklearn.utils import resample\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "EVAL_FUN_MAPPING = {\n",
    "    'r2': r2_score,\n",
    "    'balanced_accuracy': balanced_accuracy_score\n",
    "}\n",
    "\n",
    "\n",
    "def get_model_performance_ci(X_test, y_test, eval_metric, model_results_path,\n",
    "                             confidence_level=0.95, bootstrap_iters=1000, sample_size_perct=0.5):\n",
    "    sample_performance_lst = []\n",
    "    eval_fun = EVAL_FUN_MAPPING [eval_metric]\n",
    "    loaded_automl = AutoML(results_path=model_results_path)\n",
    "    \n",
    "    with tqdm(total=bootstrap_iters) as progress_bar:\n",
    "        for i in range(bootstrap_iters):\n",
    "            X_test_sample = resample(X_test, n_samples=int(len(X_test)*sample_size_perct))\n",
    "            y_test_sample = y_test.iloc[X_test_sample.index]\n",
    "            \n",
    "            y_pred_sample = loaded_automl.predict(X_test_sample)\n",
    "            \n",
    "            performance_score = eval_fun(y_test_sample, y_pred_sample)\n",
    "            sample_performance_lst.append(performance_score)\n",
    "            \n",
    "            progress_bar.update(1)\n",
    "        \n",
    "    alpha = 1 - confidence_level\n",
    "    lower_p = alpha * 100/2.0\n",
    "    lower_bound = max(0.0, np.percentile(sample_performance_lst, lower_p))\n",
    "    upper_p = (confidence_level + alpha/2.0) * 100\n",
    "    upper_bound = min(1.0, np.percentile(sample_performance_lst, upper_p))\n",
    "    \n",
    "    print(f\"\"\"There's {confidence_level*100}% likelihood that {eval_metric} score\n",
    "            between [{lower_bound}, {upper_bound}] covers the true model performance\"\"\")\n",
    "    \n",
    "    return lower_bound, upper_bound"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Confidence Interval (CI)\n",
    "\n",
    "* Using Bootstrap method to calculate the CI of the model performance\n",
    "* Reference: https://machinelearningmastery.com/calculate-bootstrap-confidence-intervals-machine-learning-results-python/\n",
    "  * The difference in the code below is, instead of re-fit the model with sample training data in each bootstrap iteration, the model was trained on all the training data once and only do prediction in each bootstrap iteration\n",
    "\n",
    "### Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(693861, 22)\n",
      "(161332, 3) (161332,)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Customers_larger_than_3000</th>\n",
       "      <th>CompetitionDistance</th>\n",
       "      <th>Customers</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1270.0</td>\n",
       "      <td>555</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1270.0</td>\n",
       "      <td>546</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1270.0</td>\n",
       "      <td>523</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1270.0</td>\n",
       "      <td>560</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1270.0</td>\n",
       "      <td>612</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Customers_larger_than_3000  CompetitionDistance  Customers\n",
       "0                         0.0               1270.0        555\n",
       "1                         0.0               1270.0        546\n",
       "2                         0.0               1270.0        523\n",
       "3                         0.0               1270.0        560\n",
       "4                         0.0               1270.0        612"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_pickle('luigi_pipeline/output/preprocessed_data.pkl')\n",
    "print(df.shape)\n",
    "\n",
    "# drop categorical features, only keep numerical features\n",
    "cat_cols = [col for col in df.select_dtypes(include='category').columns if col != 'Year']\n",
    "df.drop(cat_cols, axis=1, inplace=True)\n",
    "\n",
    "test_df = df.loc[df['Year'].astype(str) == '2015']\n",
    "\n",
    "y_test = test_df['Sales']\n",
    "X_test = test_df.drop(['Sales', 'Date', 'Year'], axis=1)\n",
    "\n",
    "X_test.reset_index(inplace=True, drop=True)\n",
    "y_test.reset_index(inplace=True, drop=True)\n",
    "\n",
    "print(X_test.shape, y_test.shape)\n",
    "X_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 20/20 [08:05<00:00, 24.28s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There's 95.0% likelihood that r2 score between [0.936296712842666, 0.938749454646744] covers the true model performance\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "lower_bound, upper_bound = get_model_performance_ci(X_test, y_test, eval_metric='r2',\n",
    "                            model_results_path='luigi_pipeline/output/mljar_regression_sales/',\n",
    "                             confidence_level=0.95, bootstrap_iters=20, sample_size_perct=0.5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(68, 15) (68,)\n",
      "30\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>specimen_number</th>\n",
       "      <th>eccentricity</th>\n",
       "      <th>aspect_ratio</th>\n",
       "      <th>elongation</th>\n",
       "      <th>solidity</th>\n",
       "      <th>stochastic_convexity</th>\n",
       "      <th>isoperimetric_factor</th>\n",
       "      <th>maximal_indentation_depth</th>\n",
       "      <th>lobedness</th>\n",
       "      <th>average_intensity</th>\n",
       "      <th>average_contrast</th>\n",
       "      <th>smoothness</th>\n",
       "      <th>third_moment</th>\n",
       "      <th>uniformity</th>\n",
       "      <th>entropy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>7</td>\n",
       "      <td>0.58637</td>\n",
       "      <td>1.1419</td>\n",
       "      <td>0.30339</td>\n",
       "      <td>0.93305</td>\n",
       "      <td>0.92105</td>\n",
       "      <td>0.57323</td>\n",
       "      <td>0.041282</td>\n",
       "      <td>0.310160</td>\n",
       "      <td>0.022886</td>\n",
       "      <td>0.093704</td>\n",
       "      <td>0.008704</td>\n",
       "      <td>0.003229</td>\n",
       "      <td>0.000104</td>\n",
       "      <td>0.54481</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>7</td>\n",
       "      <td>0.98717</td>\n",
       "      <td>6.5173</td>\n",
       "      <td>0.84726</td>\n",
       "      <td>0.96846</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>0.28899</td>\n",
       "      <td>0.022056</td>\n",
       "      <td>0.088540</td>\n",
       "      <td>0.042124</td>\n",
       "      <td>0.118420</td>\n",
       "      <td>0.013829</td>\n",
       "      <td>0.004382</td>\n",
       "      <td>0.000202</td>\n",
       "      <td>1.09800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>0.90557</td>\n",
       "      <td>2.3423</td>\n",
       "      <td>0.58487</td>\n",
       "      <td>0.95943</td>\n",
       "      <td>0.97368</td>\n",
       "      <td>0.55537</td>\n",
       "      <td>0.023542</td>\n",
       "      <td>0.100870</td>\n",
       "      <td>0.045897</td>\n",
       "      <td>0.134330</td>\n",
       "      <td>0.017724</td>\n",
       "      <td>0.006676</td>\n",
       "      <td>0.000245</td>\n",
       "      <td>0.99430</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>6</td>\n",
       "      <td>0.91296</td>\n",
       "      <td>2.4862</td>\n",
       "      <td>0.62315</td>\n",
       "      <td>0.96188</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>0.51041</td>\n",
       "      <td>0.010684</td>\n",
       "      <td>0.020775</td>\n",
       "      <td>0.064539</td>\n",
       "      <td>0.136780</td>\n",
       "      <td>0.018365</td>\n",
       "      <td>0.004864</td>\n",
       "      <td>0.000528</td>\n",
       "      <td>1.68750</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>9</td>\n",
       "      <td>0.88172</td>\n",
       "      <td>1.7740</td>\n",
       "      <td>0.63974</td>\n",
       "      <td>0.84990</td>\n",
       "      <td>0.87368</td>\n",
       "      <td>0.34354</td>\n",
       "      <td>0.051776</td>\n",
       "      <td>0.487900</td>\n",
       "      <td>0.061030</td>\n",
       "      <td>0.151900</td>\n",
       "      <td>0.022554</td>\n",
       "      <td>0.008081</td>\n",
       "      <td>0.000250</td>\n",
       "      <td>1.38050</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   specimen_number  eccentricity  aspect_ratio  elongation  solidity  \\\n",
       "0                7       0.58637        1.1419     0.30339   0.93305   \n",
       "1                7       0.98717        6.5173     0.84726   0.96846   \n",
       "2                2       0.90557        2.3423     0.58487   0.95943   \n",
       "3                6       0.91296        2.4862     0.62315   0.96188   \n",
       "4                9       0.88172        1.7740     0.63974   0.84990   \n",
       "\n",
       "   stochastic_convexity  isoperimetric_factor  maximal_indentation_depth  \\\n",
       "0               0.92105               0.57323                   0.041282   \n",
       "1               1.00000               0.28899                   0.022056   \n",
       "2               0.97368               0.55537                   0.023542   \n",
       "3               1.00000               0.51041                   0.010684   \n",
       "4               0.87368               0.34354                   0.051776   \n",
       "\n",
       "   lobedness  average_intensity  average_contrast  smoothness  third_moment  \\\n",
       "0   0.310160           0.022886          0.093704    0.008704      0.003229   \n",
       "1   0.088540           0.042124          0.118420    0.013829      0.004382   \n",
       "2   0.100870           0.045897          0.134330    0.017724      0.006676   \n",
       "3   0.020775           0.064539          0.136780    0.018365      0.004864   \n",
       "4   0.487900           0.061030          0.151900    0.022554      0.008081   \n",
       "\n",
       "   uniformity  entropy  \n",
       "0    0.000104  0.54481  \n",
       "1    0.000202  1.09800  \n",
       "2    0.000245  0.99430  \n",
       "3    0.000528  1.68750  \n",
       "4    0.000250  1.38050  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df30 = pd.read_csv('../crystal_ball/data_collector/structured_data/leaf.csv')\n",
    "\n",
    "y30 = df30['species']\n",
    "X30 = df30.drop('species', axis=1)\n",
    "\n",
    "X_train30, X_test30, y_train30, y_test30 = train_test_split(X30, y30, test_size=0.2,\n",
    "                                      random_state=10, shuffle=True, stratify=y30)\n",
    "\n",
    "X_test30.reset_index(inplace=True, drop=True)\n",
    "y_test30.reset_index(inplace=True, drop=True)\n",
    "\n",
    "print(X_test30.shape, y_test30.shape)\n",
    "print(y_test30.nunique())\n",
    "X_test30.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 10/10 [00:05<00:00,  1.75it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There's 95.0% likelihood that balanced_accuracy score between [0.7896666666666667, 0.9066061253561254] covers the true model performance\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "lower_bound, upper_bound = get_model_performance_ci(X_test30, y_test30, eval_metric='balanced_accuracy', \n",
    "                                                    model_results_path='luigi_pipeline/output/mljar_classification/',\n",
    "                                                    confidence_level=0.95, bootstrap_iters=10, sample_size_perct=0.8) "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "garden_market",
   "language": "python",
   "name": "garden_market"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
